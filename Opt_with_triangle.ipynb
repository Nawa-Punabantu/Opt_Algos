{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEQm49Fi62yuggzcN5IYvO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nawa-Punabantu/Opt_Algos/blob/main/Opt_with_triangle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "import scipy as sp\n",
        "print(sp.__version__)\n",
        "\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, Matern\n",
        "from scipy.optimize import differential_evolution\n",
        "from scipy.optimize import minimize, NonlinearConstraint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "from scipy.integrate import solve_ivp\n",
        "from scipy import integrate\n",
        "import warnings\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwjkYaoiawYC",
        "outputId": "8789fc1f-d335-4ab0-e2b4-655b2ff053e4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n",
            "1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# smb model\n",
        "# # tips:\n",
        "    # - the Error: \"IndexError: index 10 is out of bounds for axis 0 with size 9\"\n",
        "    # may be due to a miss-match in size between the initial conditons and c, q in the ode func.\n",
        "# IMPORTING LIBRARIES\n",
        "###########################################\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.integrate import solve_ivp\n",
        "import matplotlib.pyplot as plt\n",
        "# Loading the Plotting Libraries\n",
        "from matplotlib.pyplot import subplots\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "# from PIL import Image\n",
        "from scipy import integrate\n",
        "# import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "###########################################\n",
        "# IMPORTING MY OWN FUNCTIONS\n",
        "###########################################\n",
        "# from post_pre_processing_funcs import\n",
        "\n",
        "# INPUTS\n",
        "#######################################################\n",
        "\n",
        "# UNITS:\n",
        "# All units must conform to:\n",
        "# Time - s\n",
        "# Lengths - cm^2\n",
        "# Volumes - cm^3\n",
        "# Masses - g\n",
        "# Concentrations - g\n",
        "# Volumetric flowrates - cm^3/s\n",
        "\n",
        "\n",
        "def SMB(SMB_inputs):\n",
        "    iso_type, Names, color, num_comp, nx_per_col, e, Pe_all, Bm, zone_config, L, d_col, d_in, t_index_min, n_num_cycles, Q_internal, parameter_sets = SMB_inputs[0:]\n",
        "\n",
        "    ###################### (CALCUALTED) SECONDARY INPUTS #########################\n",
        "\n",
        "    # Column Dimensions:\n",
        "    ################################################################\n",
        "    F = (1-e)/e     # Phase ratio\n",
        "    t=0\n",
        "    t_sets = 0\n",
        "    Ncol_num = np.sum(zone_config) # Total number of columns\n",
        "    L_total = L*Ncol_num # Total Lenght of all columns\n",
        "    A_col = np.pi*0.25*d_col**2 # cm^2\n",
        "    V_col = A_col * L # cm^3\n",
        "    V_col_total = Ncol_num * V_col # cm^3\n",
        "    A_in = np.pi * (d_in/2)**2 # cm^2\n",
        "    alpha = A_in / A_col\n",
        "\n",
        "\n",
        "\n",
        "    # Time Specs:\n",
        "    ################################################################\n",
        "\n",
        "    t_index = t_index_min*60 # s #\n",
        "\n",
        "    # Notes:\n",
        "    # - Cyclic Steady state typically happens only after 10 cycles (ref: https://doi.org/10.1205/026387603765444500)\n",
        "    # - The system is not currently designed to account for periods of no external flow\n",
        "\n",
        "    n_1_cycle = t_index * Ncol_num  # s How long a single cycle takes\n",
        "\n",
        "    total_cycle_time = n_1_cycle*n_num_cycles # s\n",
        "\n",
        "    tend = total_cycle_time # s # Final time point in ODE solver\n",
        "\n",
        "    tend_min = tend/60\n",
        "\n",
        "    t_span = (0, tend) # +dt)  # from t=0 to t=n\n",
        "\n",
        "    num_of_injections = int(np.round(tend/t_index)) # number of switching periods\n",
        "\n",
        "    # 't_start_inject_all' is a vecoter containing the times when port swithes occur for each port\n",
        "    # Rows --> Different Ports\n",
        "    # Cols --> Different time points\n",
        "    t_start_inject_all = [[] for _ in range(Ncol_num)]  # One list for each node (including the main list)\n",
        "\n",
        "    # Calculate start times for injections\n",
        "    for k in range(num_of_injections):\n",
        "        t_start_inject = k * t_index\n",
        "        t_start_inject_all[0].append(t_start_inject)  # Main list\n",
        "        for node in range(1, Ncol_num):\n",
        "            t_start_inject_all[node].append(t_start_inject + node * 0)  # all rows in t_start_inject_all are identical\n",
        "\n",
        "    t_schedule = t_start_inject_all[0]\n",
        "\n",
        "    # REQUIRED FUNCTIONS:\n",
        "    ################################################################\n",
        "\n",
        "    # 1.\n",
        "    # Func to Generate Indices for the columns\n",
        "    # def generate_repeated_numbers(n, m):\n",
        "    #     result = []\n",
        "    #     n = int(n)\n",
        "    #     m = int(m)\n",
        "    #     for i in range(m):\n",
        "    #         result.extend([i] * n)\n",
        "    #     return result\n",
        "\n",
        "    # 3.\n",
        "    # Func to divide the column into nodes\n",
        "\n",
        "    # DOES NOT INCLUDE THE C0 NODE (BY DEFAULT)\n",
        "    def set_x(L, Ncol_num,nx_col,dx):\n",
        "        if nx_col == None:\n",
        "            x = np.arange(0, L+dx, dx)\n",
        "            nnx = len(x)\n",
        "            nnx_col = int(np.round(nnx/Ncol_num))\n",
        "            nx_BC = Ncol_num - 1 # Number of Nodes (mixing points/boundary conditions) in between columns\n",
        "\n",
        "            # Indecies belonging to the mixing points between columns are stored in 'start'\n",
        "            # These can be thought of as the locations of the nx_BC nodes.\n",
        "            return x, dx, nnx_col,  nnx, nx_BC\n",
        "\n",
        "        elif dx == None:\n",
        "            nx = Ncol_num * nx_col\n",
        "            nx_BC = Ncol_num - 1 # Number of Nodes in between columns\n",
        "            x = np.linspace(0,L_total,nx)\n",
        "            ddx = x[1] - x[0]\n",
        "\n",
        "            # Indecies belonging to the mixing points between columns are stored in 'start'\n",
        "            # These can be thought of as the locations of the nx_BC nodes.\n",
        "\n",
        "            return x, ddx, nx_col, nx, nx_BC\n",
        "\n",
        "    # 4. A func that:\n",
        "    # (i) Calcualtes the internal flowrates given the external OR (ii) Visa-versa\n",
        "    def set_flowrate_values(set_Q_int, set_Q_ext, Q_rec):\n",
        "        if set_Q_ext is None and Q_rec is None:  # Chosen to specify internal/zone flowrates\n",
        "            Q_I = set_Q_int[0]\n",
        "            Q_II = set_Q_int[1]\n",
        "            Q_III = set_Q_int[2]\n",
        "            Q_IV = set_Q_int[3]\n",
        "\n",
        "            QX = -(Q_I - Q_II)\n",
        "            QF = Q_III - Q_II\n",
        "            QR = -(Q_III - Q_IV)\n",
        "            QD = -(QF + QX + QR) # OR: Q_I - Q_IV\n",
        "\n",
        "            Q_ext = np.array([QF, QR, QD, QX]) # cm^3/s\n",
        "\n",
        "            return Q_ext\n",
        "\n",
        "        elif set_Q_int is None and Q_rec is not None:  # Chosen to specify external flowrates\n",
        "            QF = set_Q_ext[0]\n",
        "            QR = set_Q_ext[1]\n",
        "            QD = set_Q_ext[2]\n",
        "            QX = set_Q_ext[3]\n",
        "\n",
        "            Q_I = Q_rec  # m^3/s\n",
        "            Q_III = (QX + QF) + Q_I\n",
        "            Q_IV = (QD - QX) + Q_I  # Fixed Q_II to Q_I as the variable was not defined yet\n",
        "            Q_II = (QR - QX) + Q_IV\n",
        "            Q_internal = np.array([Q_I, Q_II, Q_III, Q_IV])\n",
        "            return Q_internal\n",
        "\n",
        "\n",
        "    # 5. Function to Build Port Schedules:\n",
        "\n",
        "    # This is done in two functions: (i) repeat_array and (ii) build_matrix_from_vector\n",
        "    # (i) repeat_array\n",
        "    # Summary: Creates the schedule for the 1st port, port 0, only. This is the port boadering Z2 & Z3 and always starts as a Feed port at t=0\n",
        "    # (i) build_matrix_from_vector\n",
        "    # Summary: Takes the output from \"repeat_array\" and creates schedules for all other ports.\n",
        "    # The \"trick\" is that the states of each of the, n, ports at t=0, is equal to the first, n, states of port 0.\n",
        "    # Once we know the states for each port at t=0, we form a loop that adds the next state.\n",
        "\n",
        "    # 5.1\n",
        "    def position_maker(schedule_quantity_name, F, R, D, X, Z_config):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        Function that initializes the starting schedueles for a given quantitiy at all positions\n",
        "\n",
        "        F, R, D and X are the values of the quantiity at the respective feed ports\n",
        "\n",
        "        \"\"\"\n",
        "        # Initialize:\n",
        "        X_j = np.zeros(Ncol_num)\n",
        "\n",
        "\n",
        "        # We set each port in the appropriate position, depending on the nuber of col b/n Zones:\n",
        "        # By default, Position i = 0 (entrance to col,0) is reserved for the feed node.\n",
        "\n",
        "        # Initialize Positions:\n",
        "        # Q_position is a vector whose len is = number of mixing points (ports) b/n columns\n",
        "\n",
        "        X_j[0] = F        # FEED\n",
        "        X_j[Z_config[2]] = R     # RAFFINATE\n",
        "        X_j[Z_config[2] + Z_config[3]] = D    # DESORBENT\n",
        "        X_j[Z_config[2] + Z_config[3]+  Z_config[0]] = X   # EXTRACT\n",
        "\n",
        "        return X_j\n",
        "\n",
        "    # 5.2\n",
        "    def repeat_array(vector, start_time_num):\n",
        "        # vector = the states of all ports at t=0, vector[0] = is always the Feed port\n",
        "        # start_time_num = The number of times the state changes == num of port switches == num_injections\n",
        "        repeated_array = np.tile(vector, (start_time_num // len(vector) + 1))\n",
        "        return repeated_array[:start_time_num]\n",
        "\n",
        "    def initial_u_col(Zconfig, Qint):\n",
        "        \"\"\"\n",
        "        Fun that returns the the inital state at t=0 of the volumetric\n",
        "        flows in all the columns.\n",
        "\n",
        "        \"\"\"\n",
        "        # First row is for col0, which is the feed to zone 3\n",
        "        Zconfig_roll = np.roll(Zconfig, -2)\n",
        "        Qint_roll = np.roll(Qint, -2)\n",
        "\n",
        "        # print(Qint)\n",
        "        X = np.array([])\n",
        "\n",
        "        for i in range(len(Qint_roll)):\n",
        "            X_add = np.ones(Zconfig_roll[i])*Qint_roll[i]\n",
        "            # print('X_add:\\n', X_add)\n",
        "\n",
        "            X = np.append(X, X_add)\n",
        "        # X = np.concatenate(X)\n",
        "        # print('X:\\n', X)\n",
        "        return X\n",
        "\n",
        "\n",
        "    def build_matrix_from_vector(vector, t_schedule):\n",
        "        \"\"\"\n",
        "        Fun that returns the schedeule given the inital state at t=0\n",
        "        vector: inital state of given quantity at t=0 at all nodes\n",
        "        t_schedule: times at which port changes happen\n",
        "\n",
        "        \"\"\"\n",
        "        # vector = the states of all ports at t=0, vector[0] = is always the Feed port\n",
        "        start_time_num = int(len(t_schedule))\n",
        "        vector = np.array(vector)  # Convert the vector to a NumPy array\n",
        "        n = len(vector) # number of ports/columns\n",
        "\n",
        "        # Initialize the matrix for repeated elements, ''ALL''\n",
        "        ALL = np.zeros((n, start_time_num), dtype=vector.dtype)  # Shape is (n, start_time_num)\n",
        "\n",
        "        for i in range(start_time_num):\n",
        "            # print('i:',i)\n",
        "            ALL[:, i] = np.roll(vector, i)\n",
        "        return ALL\n",
        "\n",
        "\n",
        "\n",
        "    # # Uncomment as necessary depending on specification of either:\n",
        "    # # (1) Internal OR (2) External flowrates :\n",
        "    # # (1)\n",
        "    # Q_internal = np.array([Q_I, Q_II, Q_III, Q_IV])\n",
        "    Q_external = set_flowrate_values(Q_internal, None, None) # Order: QF, QR, QD, QX\n",
        "    QF, QR, QD, QX = Q_external[0], Q_external[1], Q_external[2], Q_external[3]\n",
        "    # print('Q_external:', Q_external)\n",
        "\n",
        "    # (2)\n",
        "    # QX, QF, QR = -0.277, 0.315, -0.231  # cm^3/s\n",
        "    # QD = - (QF + QX + QR)\n",
        "    # Q_external = np.array([QF, QR, QD, QX])\n",
        "    # Q_rec = 33.69 # cm^3/s\n",
        "    # Q_internal = set_flowrate_values(None, Q_external, Q_rec) # Order: QF, QR, QD, Q\n",
        "\n",
        "    ################################################################################################\n",
        "\n",
        "\n",
        "    # Make concentration schedules for each component\n",
        "\n",
        "    Cj_pulse_all = [[] for _ in range(num_comp)]\n",
        "    for i in range(num_comp):\n",
        "        Cj_position = []\n",
        "        Cj_position = position_maker('Feed Conc Schedule:', parameter_sets[i]['C_feed'], 0, 0, 0, zone_config)\n",
        "        Cj_pulse = build_matrix_from_vector(Cj_position,  t_schedule)\n",
        "        Cj_pulse_all[i] = Cj_pulse\n",
        "\n",
        "\n",
        "    Q_position = position_maker('Vol Flow Schedule:', Q_external[0], Q_external[1], Q_external[2], Q_external[3], zone_config)\n",
        "    Q_pulse_all = build_matrix_from_vector(Q_position,  t_schedule)\n",
        "\n",
        "    # Spacial Discretization:\n",
        "    # Info:\n",
        "    # nx --> Total Number of Nodes (EXCLUDING mixing points b/n nodes)\n",
        "    # nx_col --> Number of nodes in 1 column\n",
        "    # nx_BC --> Number of mixing points b/n nodes\n",
        "    x, dx, nx_col, nx, nx_BC = set_x(L=L_total, Ncol_num = Ncol_num, nx_col = nx_per_col, dx = None)\n",
        "    start = [i*nx_col for i in range(0,Ncol_num)] # Locations of the BC indecies\n",
        "    u_col_at_t0 = initial_u_col(zone_config, Q_internal)\n",
        "    Q_col_all = build_matrix_from_vector(u_col_at_t0, t_schedule)\n",
        "\n",
        "\n",
        "    # DISPLAYING INPUT INFORMATION:\n",
        "    # print('---------------------------------------------------')\n",
        "    # print('Number of Components:', num_comp)\n",
        "    # print('---------------------------------------------------')\n",
        "    # print('\\nTime Specs:\\n')\n",
        "    # print('---------------------------------------------------')\n",
        "    # print('Number of Cycles:', n_num_cycles)\n",
        "    # print('Time Per Cycle:', n_1_cycle/60, \"min\")\n",
        "    # print('Simulation Time:', tend_min, 'min')\n",
        "    # print('Index Time:', t_index, 's OR', t_index/60, 'min' )\n",
        "    # print('Number of Port Switches:', num_of_injections)\n",
        "    # print('Injections happen at t(s) = :', t_schedule, 'seconds')\n",
        "    # print('---------------------------------------------------')\n",
        "    # print('\\nColumn Specs:\\n')\n",
        "    # print('---------------------------------------------------')\n",
        "    # print('Configuration:', zone_config, '[Z1,Z2,Z3,Z4]')\n",
        "    # print(f\"Number of Columns: {Ncol_num}\")\n",
        "    # print('Column Length:', L, 'cm')\n",
        "    # print('Column Diameter:', d_col, 'cm')\n",
        "    # print('Column Volume:', V_col, 'cm^3')\n",
        "    # print(\"alpha:\", alpha, '(alpha = A_in / A_col)')\n",
        "    # print(\"Nodes per Column:\",nx_col)\n",
        "    # print(\"Boundary Nodes locations,x[i], i =\", start)\n",
        "    # print(\"Total Number of Nodes (nx):\",nx)\n",
        "    # print('---------------------------------------------------')\n",
        "    # print('\\nFlowrate Specs:\\n')\n",
        "    # print('---------------------------------------------------')\n",
        "    # print(\"External Flowrates =\", Q_external, '[F,R,D,X] ml/min')\n",
        "    # print(\"Ineternal Flowrates =\", Q_internal, 'ml/min')\n",
        "    # print('---------------------------------------------------')\n",
        "    # print('\\nPort Schedules:')\n",
        "    # for i in range(num_comp):\n",
        "    #     print(f\"Concentration Schedule:\\nShape:\\n {Names[i]}:\\n\",np.shape(Cj_pulse_all[i]),'\\n', Cj_pulse_all[i], \"\\n\")\n",
        "    # print(\"Injection Flowrate Schedule:\\nShape:\",np.shape(Q_pulse_all),'\\n', Q_pulse_all, \"\\n\")\n",
        "    # print(\"Respective Column Flowrate Schedule:\\nShape:\",np.shape(Q_col_all),'\\n', Q_col_all, \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "    # ###########################################################################################\n",
        "\n",
        "    # Isotherm Models:\n",
        "\n",
        "\n",
        "    ###########################################################################################\n",
        "\n",
        "    # 1. LINEAR\n",
        "    def iso_lin(theta_lin, c):\n",
        "        # params: [HA, HB]\n",
        "        H = theta_lin\n",
        "        q_star = H*c\n",
        "\n",
        "        return q_star # [qA, qB, ...]\n",
        "\n",
        "    # 2.  LANGMUIR\n",
        "\n",
        "    # 2.1 Independent Langmuir\n",
        "    def iso_langmuir(theta_lang, c, comp_idx): # already for specific comp\n",
        "        H = theta_lang\n",
        "        q_star = H*c/(1 + H*c)\n",
        "        #q_star = H[comp_idx]*c/(1 + K[0]*c + K[1]*c)\n",
        "        # q_star = theta_lang[0]*c/(1 + theta_lang[1]*c + theta_lang[2]*c) +\\\n",
        "        #     theta_lang[3]*c/(1 + theta_lang[4]*c + theta_lang[5]*c)\n",
        "        return q_star\n",
        "\n",
        "    # 2.3 Coupled Langmuir\n",
        "    def iso_cup_langmuir(theta_cuplang, c, IDX, comp_idx): # already for specific comp\n",
        "        H = theta_cuplang[:2] # [HA, HB]\n",
        "        K = theta_cuplang[2:] # [KA, KB]\n",
        "        cA = c[IDX[0] + 0: IDX[0] + nx ]\n",
        "        cB = c[IDX[1] + 0: IDX[1] + nx ]\n",
        "        c_i = [cA, cB]\n",
        "        q_star = H[comp_idx]*c_i[comp_idx]/(1 + K[0]*cA + K[1]*cB)\n",
        "        return q_star\n",
        "\n",
        "    # 2.3 Bi-Langmuir\n",
        "    def iso_bi_langmuir(theta_bl, c, IDX, comp_idx): # already for specific comp\n",
        "        cA = c[IDX[0] + 0: IDX[0] + nx ]\n",
        "        cB = c[IDX[1] + 0: IDX[1] + nx ]\n",
        "        c_i = [cA, cB]\n",
        "\n",
        "        q_star = theta_bl[0]*c_i[comp_idx]/(1 + theta_bl[1]*cA + theta_bl[2]*cB) +\\\n",
        "                theta_bl[3]*c_i[comp_idx]/(1 + theta_bl[4]*cA + theta_bl[5]*cB)\n",
        "\n",
        "        return q_star\n",
        "\n",
        "\n",
        "    # 3. FREUDLICH:\n",
        "    def iso_freundlich(theta_fre, c): # already for specific comp\n",
        "        q_star = theta_fre[0]*c**(1/theta_fre[1])\n",
        "        return q_star\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ###########################################################################################\n",
        "\n",
        "    ###########################################################################################\n",
        "\n",
        "    # Mass Transfer (MT) Models:\n",
        "\n",
        "    def mass_transfer(kav_params, q_star, q): # already for specific comp\n",
        "        # kav_params: [kA, kB]\n",
        "        kav =  kav_params\n",
        "        MT = kav * Bm/(5 + Bm) * (q_star - q)\n",
        "        # MT = kav * (q_star - q)\n",
        "        return MT\n",
        "\n",
        "    # MT PARAMETERS\n",
        "    ###########################################################################################\n",
        "    # print('np.shape(parameter_sets[:][\"kh\"]):', np.shape(parameter_sets[3]))\n",
        "    kav_params = [parameter_sets[i][\"kh\"] for i in range(num_comp)]  # [kA, kB, kC, kD, kE, kF]\n",
        "    # print('kav_params:', kav_params)\n",
        "    # print('----------------------------------------------------------------')\n",
        "    ###########################################################################################\n",
        "\n",
        "    # # FORMING THE ODES\n",
        "\n",
        "\n",
        "    # Form the remaining schedule matrices that are to be searched by the funcs\n",
        "\n",
        "    # Column velocity schedule:\n",
        "    u_col_all = -Q_col_all/A_col/e\n",
        "\n",
        "    # Column Dispersion schedule:\n",
        "    # Different matrices for each comp because diff Pe's for each comp\n",
        "    D_col_all = []\n",
        "    for i in range(num_comp): # for each comp\n",
        "        D_col = -(u_col_all*L)/Pe_all[i] # constant dispersion coeff\n",
        "        D_col_all.append(D_col)\n",
        "\n",
        "    # Storage Spaces:\n",
        "    coef_0 = np.zeros_like(u_col_all)\n",
        "    coef_1 = np.zeros_like(u_col_all)\n",
        "    coef_2 = np.zeros_like(u_col_all)\n",
        "\n",
        "    # coef_0, coef_1, & coef_2 correspond to the coefficents of ci-1, ci & ci+1 respectively\n",
        "    # These depend on u and so change with time, thus have a schedule\n",
        "\n",
        "    # From descritization:\n",
        "    coef_0_all = []\n",
        "    coef_1_all = []\n",
        "    coef_2_all = []\n",
        "    for j in range(num_comp): # for each comp\n",
        "        for i  in range(Ncol_num): # coefficients for each col\n",
        "            coef_0[i,:] = ( D_col_all[j][i,:]/dx**2 ) - ( u_col_all[i,:]/dx ) # coefficeint of i-1\n",
        "            coef_1[i,:] = ( u_col_all[i,:]/dx ) - (2*D_col_all[j][i,:]/(dx**2))# coefficeint of i\n",
        "            coef_2[i,:] = (D_col_all[j][i,:]/(dx**2))    # coefficeint of i+1\n",
        "        coef_0_all.append(coef_0)\n",
        "        coef_1_all.append(coef_1)\n",
        "        coef_2_all.append(coef_2)\n",
        "\n",
        "    # All shedules:\n",
        "    # For each shceudle, rows => col idx, columns => Time idx\n",
        "    # :\n",
        "    # - Q_pulse_all: Injection flowrates\n",
        "    # - C_pulse_all: Injection concentrations for each component\n",
        "    # - Q_col_all:  Flowrates WITHIN each col\n",
        "    # - u_col_all: Linear velocities WITHIN each col\n",
        "    # - D_col_all: Dispersion coefficeints WITHIN each col\n",
        "    # - coef_0, 1 and 2: ci, ci-1 & ci+1 ceofficients\n",
        "\n",
        "    # print('coef_0:\\n',coef_0)\n",
        "    # print('coef_1:\\n',coef_1)\n",
        "    # print('coef_2:\\n',coef_2)\n",
        "    # print('\\nD_col_all:\\n',D_col_all)\n",
        "    # print('Q_col_all:\\n',Q_col_all)\n",
        "    # print('A_col:\\n',A_col)\n",
        "    # print('u_col_all:\\n',u_col_all)\n",
        "\n",
        "\n",
        "    def coeff_matrix_builder_UNC(t, Q_col_all, Q_pulse_all, dx, start, alpha, c, nx_col, comp_idx): # note that c_length must include nx_BC\n",
        "\n",
        "        # Define the functions that call the appropriate schedule matrices:\n",
        "        # Because all scheudels are of the same from, only one function is required\n",
        "        # Calling volumetric flows:\n",
        "        get_X = lambda t, X_schedule, col_idx: next((X_schedule[col_idx][j] for j in range(len(X_schedule[col_idx])) if t_start_inject_all[col_idx][j] <= t < t_start_inject_all[col_idx][j] + t_index), 1/100000000)\n",
        "        get_C = lambda t, C_schedule, col_idx, comp_idx: next((C_schedule[comp_idx][col_idx][j] for j in range(len(C_schedule[comp_idx][col_idx])) if t_start_inject_all[col_idx][j] <= t < t_start_inject_all[col_idx][j] + t_index), 1/100000000)\n",
        "\n",
        "        def small_col_matix(nx_col, col_idx):\n",
        "        # Initialize small_col_coeff ('small' = for 1 col)\n",
        "\n",
        "            small_col_coeff = np.zeros((int(nx_col),int(nx_col))) #(5,5)\n",
        "\n",
        "            # Where the 1st (0th) row and col are for c1\n",
        "            # get_C(t, coef_0_all, k, comp_idx)\n",
        "            # small_col_coeff[0,0], small_col_coeff[0,1] = get_X(t,coef_1,col_idx), get_X(t,coef_2,col_idx)\n",
        "            small_col_coeff[0,0], small_col_coeff[0,1] = get_C(t,coef_1_all,col_idx, comp_idx), get_C(t,coef_2_all,col_idx, comp_idx)\n",
        "            # for c2:\n",
        "            # small_col_coeff[1,0], small_col_coeff[1,1], small_col_coeff[1,2] = get_X(t,coef_0,col_idx), get_X(t,coef_1,col_idx), get_X(t,coef_2,col_idx)\n",
        "            small_col_coeff[1,0], small_col_coeff[1,1], small_col_coeff[1,2] = get_C(t,coef_0_all,col_idx, comp_idx), get_C(t, coef_1_all, col_idx, comp_idx), get_C(t, coef_2_all,col_idx, comp_idx)\n",
        "\n",
        "            for i in range(2,nx_col): # from row i=2 onwards\n",
        "                # np.roll the row entries from the previous row, for all the next rows\n",
        "                new_row = np.roll(small_col_coeff[i-1,:],1)\n",
        "                small_col_coeff[i:] = new_row\n",
        "\n",
        "            small_col_coeff[-1,0] = 0\n",
        "            small_col_coeff[-1,-1] = small_col_coeff[-1,-1] +  get_C(t,coef_2_all,col_idx, comp_idx) # coef_1 + coef_2 account for rolling boundary\n",
        "\n",
        "\n",
        "            return small_col_coeff\n",
        "\n",
        "\n",
        "        larger_coeff_matrix = np.zeros((nx,nx)) # ''large'' = for all cols # (20, 20)\n",
        "\n",
        "        # Add the cols\n",
        "        for col_idx in range(Ncol_num):\n",
        "            larger_coeff_matrix[col_idx*nx_col:(col_idx+1)*nx_col, col_idx*nx_col:(col_idx+1)*nx_col] = small_col_matix(nx_col,col_idx)\n",
        "        # print('np.shape(larger_coeff_matrix)\\n',np.shape(larger_coeff_matrix))\n",
        "\n",
        "        # vector_add: vector that applies the boundary conditions to each boundary node\n",
        "        def vector_add(nx, c, start, comp_idx):\n",
        "            vec_add = np.zeros(nx)\n",
        "            c_BC = np.zeros(Ncol_num)\n",
        "            # Indeceis for the boundary nodes are stored in \"start\"\n",
        "            # Each boundary node is affected by the form:\n",
        "            # c_BC = V1 * C_IN - V2 * c[i] + V3 * c[i+1]\n",
        "\n",
        "            # R1 = ((beta * alpha) / gamma)\n",
        "            # R2 = ((2 * Da / (u * dx)) / gamma)\n",
        "            # R3 = ((Da / (2 * u * dx)) / gamma)\n",
        "\n",
        "            # Where:\n",
        "            # C_IN is the weighted conc exiting the port facing the column entrance.\n",
        "            # alpha , bata and gamma depend on the column vecolity and are thus time dependant\n",
        "            # Instead of forming schedules for alpha , bata and gamma, we calculate them in-line\n",
        "\n",
        "            for i in range(len(start)):\n",
        "                #  start[i] => the node at the entrance to the ith col\n",
        "                # So start[3] is the node representing the 1st node in col 3\n",
        "\n",
        "                Q_1 = get_X(t, Q_col_all, i-1) # Vol_flow from previous column (which for column 0, is the last column in the chain)\n",
        "                Q_2 = get_X(t, Q_pulse_all, i) # Vol_flow injected IN port i\n",
        "\n",
        "                Q_out_port = get_X(t, Q_col_all, i) # Vol_flow OUT of port 0 (Also could have used Q_1 + Q_2)\n",
        "\n",
        "\n",
        "                W1 = Q_1/Q_out_port # Weighted flowrate to column i\n",
        "                W2 = Q_2/Q_out_port # Weighted flowrate to column i\n",
        "\n",
        "                # Calcualte Weighted Concentration:\n",
        "\n",
        "                c_injection = get_C(t, Cj_pulse_all, i, comp_idx)\n",
        "\n",
        "                if Q_2 > 0: # Concentration in the next column is only affected for injection flows IN\n",
        "                    C_IN = W1 * c[i*nx_col-1] + W2 * c_injection\n",
        "                else:\n",
        "                    # C_IN = c[i*nx_col-1] # no change in conc during product collection\n",
        "                    C_IN = c[start[i]-1] # no change in conc during product collection\n",
        "\n",
        "                # Calcualte alpha, bata and gamma:\n",
        "                # Da = get_X(t, D_col_all, i)\n",
        "                Da = get_C(t, D_col_all, i, comp_idx)\n",
        "                u =  get_X(t, u_col_all, i)\n",
        "                beta = 1 / alpha\n",
        "                gamma = 1 - 3 * Da / (2 * u * dx)\n",
        "\n",
        "                ##\n",
        "                R1 = ((beta * alpha) / gamma)\n",
        "                R2 = ((2 * Da / (u * dx)) / gamma)\n",
        "                R3 = ((Da / (2 * u * dx)) / gamma)\n",
        "                ##\n",
        "\n",
        "                # Calcualte the BC effects:\n",
        "                j = start[i]\n",
        "                c_BC[i] = R1 * C_IN - R2 * c[j] + R3 * c[j+1] # the boundary concentration for that node\n",
        "\n",
        "            # print('c_BC:\\n', c_BC)\n",
        "\n",
        "            for k in range(len(c_BC)):\n",
        "                # vec_add[start[k]]  = get_X(t,coef_0,k)*c_BC[k]\n",
        "                vec_add[start[k]]  = get_C(t, coef_0_all, k, comp_idx)*c_BC[k]\n",
        "\n",
        "            return vec_add\n",
        "            # print('np.shape(vect_add)\\n',np.shape(vec_add(nx, c, start)))\n",
        "        return larger_coeff_matrix, vector_add(nx, c, start, comp_idx)\n",
        "\n",
        "    def coeff_matrix_builder_CUP(t, Q_col_all, Q_pulse_all, dx, start_CUP, alpha, c, nx_col,IDX): # note that c_length must include nx_BC\n",
        "\n",
        "        # Define the functions that call the appropriate schedule matrices:\n",
        "        # Because all scheudels are of the same from, only one function is required\n",
        "        # Calling volumetric flows:\n",
        "        get_X = lambda t, X_schedule, col_idx: next((X_schedule[col_idx][j] for j in range(len(X_schedule[col_idx])) if t_start_inject_all[col_idx][j] <= t < t_start_inject_all[col_idx][j] + t_index), 1/100000000)\n",
        "\n",
        "\n",
        "        # 1. From coefficent \"small\" matrix for movement of single comp through single col\n",
        "        # 2. Form  \"large\" coefficent matrix for movement through one all cols\n",
        "        # 3. The large  coefficent matrix for each comp will then be combined into Final Matrix\n",
        "\n",
        "        # 1.\n",
        "        def small_col_matrix(nx_col, col_idx):\n",
        "\n",
        "        # Initialize small_col_coeff ('small' = for 1 col)\n",
        "\n",
        "            small_col_coeff = np.zeros((int(nx_col),int(nx_col))) #(5,5)\n",
        "\n",
        "            # Where the 1st (0th) row and col are for c1\n",
        "            #\n",
        "            small_col_coeff[0,0], small_col_coeff[0,1] = get_X(t,coef_1,col_idx), get_X(t,coef_2,col_idx)\n",
        "            # for c2:\n",
        "            small_col_coeff[1,0], small_col_coeff[1,1], small_col_coeff[1,2] = get_X(t,coef_0,col_idx), get_X(t,coef_1,col_idx), get_X(t,coef_2,col_idx)\n",
        "\n",
        "            for i in range(2,nx_col): # from row i=2 onwards\n",
        "                # np.roll the row entries from the previous row, for all the next rows\n",
        "                new_row = np.roll(small_col_coeff[i-1,:],1)\n",
        "                small_col_coeff[i:] = new_row\n",
        "\n",
        "            small_col_coeff[-1,0] = 0\n",
        "            small_col_coeff[-1,-1] = small_col_coeff[-1,-1] +  get_X(t,coef_2,col_idx) # coef_1 + coef_2 account for rolling boundary\n",
        "\n",
        "            return small_col_coeff\n",
        "\n",
        "        # 2. Func to Build Large Matrix\n",
        "\n",
        "        def matrix_builder(M, M0):\n",
        "            # M = Matrix to add (small)\n",
        "            # M0 = Initial state of the larger matrix to be added to\n",
        "            nx_col = M.shape[0]\n",
        "            repeat = int(np.round(M0.shape[0]/M.shape[0]))# numbner of times the small is added to the larger matrix\n",
        "            for col_idx in range(repeat):\n",
        "                        M0[col_idx*nx_col:(col_idx+1)*nx_col, col_idx*nx_col:(col_idx+1)*nx_col] = M\n",
        "            return M0\n",
        "\n",
        "\n",
        "        # 3. Generate and Store the Large Matrices\n",
        "        # Storage Space:\n",
        "        # NOTE: Assuming all components have the same Dispersion coefficients,\n",
        "        # all components will have the same large_col_matrix\n",
        "        # Add the cols\n",
        "        larger_coeff_matrix = np.zeros((nx,nx)) # ''large'' = for all cols # (20, 20)\n",
        "\n",
        "        for col_idx in range(Ncol_num):\n",
        "            larger_coeff_matrix[col_idx*nx_col:(col_idx+1)*nx_col, col_idx*nx_col:(col_idx+1)*nx_col] = small_col_matrix(nx_col,col_idx)\n",
        "\n",
        "        # print('np.shape(larger_coeff_matrix)\\n',np.shape(larger_coeff_matrix))\n",
        "\n",
        "        # Inital final matrix:\n",
        "        n = nx*num_comp\n",
        "        final_matrix0 = np.zeros((n,n))\n",
        "\n",
        "\n",
        "        final_matrix = matrix_builder(larger_coeff_matrix, final_matrix0)\n",
        "\n",
        "            # vector_add: vector that applies the boundary conditions to each boundary node\n",
        "        def vector_add(nx, c, start):\n",
        "            vec_add = np.zeros(nx*num_comp)\n",
        "            c_BC = np.zeros(nx*num_comp)\n",
        "            # Indeceis for the boundary nodes are stored in \"start\"\n",
        "            # Each boundary node is affected by the form:\n",
        "            # c_BC = V1 * C_IN - V2 * c[i] + V3 * c[i+1]\n",
        "\n",
        "            # R1 = ((beta * alpha) / gamma)\n",
        "            # R2 = ((2 * Da / (u * dx)) / gamma)\n",
        "            # R3 = ((Da / (2 * u * dx)) / gamma)\n",
        "\n",
        "            # Where:\n",
        "            # C_IN is the weighted conc exiting the port facing the column entrance.\n",
        "            # alpha , bata and gamma depend on the column vecolity and are thus time dependant\n",
        "            # Instead of forming schedules for alpha , bata and gamma, we calculate them in-line\n",
        "\n",
        "            for i in range(len(start)):\n",
        "                #k = i%len(start) # Recounts columns for B\n",
        "                Q_1 = get_X(t, Q_col_all, i-1) # Vol_flow from previous column (which for column 0, is the last column in the chain)\n",
        "                Q_2 = get_X(t, Q_pulse_all, i) # Vol_flow injected IN port i\n",
        "\n",
        "                Q_out_port = get_X(t, Q_col_all, i) # Vol_flow OUT of port 0 (Also could have used Q_1 + Q_2)\n",
        "\n",
        "\n",
        "                W1 = Q_1/Q_out_port # Weighted flowrate to column i\n",
        "                W2 = Q_2/Q_out_port # Weighted flowrate to column i\n",
        "\n",
        "                # Calcualte Weighted Concentration:\n",
        "                # Identifiers:\n",
        "                A = IDX[0]\n",
        "                B = IDX[1]\n",
        "\n",
        "                # C_IN_A = W1 * c[A + i*nx_col-1] + W2 * get_X(t, C_pulse_all_A, i) # c[-1] conc out the last col\n",
        "                # C_IN_B = W1 * c[B + i*nx_col-1] + W2 * get_X(t, C_pulse_all_B, i) # c[-1] conc out the last col\n",
        "\n",
        "                C_IN_A = W1 * c[A + i*nx_col-1] + W2 * get_X(t, Cj_pulse_all[0], i) # c[-1] conc out the last col\n",
        "                C_IN_B = W1 * c[B + i*nx_col-1] + W2 * get_X(t, Cj_pulse_all[1], i) # c[-1] conc out the last col\n",
        "\n",
        "\n",
        "                # Calcualte alpha, bata and gamma:\n",
        "                Da = get_X(t, D_col_all, i)\n",
        "                u =  get_X(t, u_col_all, i)\n",
        "                beta = 1 / alpha\n",
        "                gamma = 1 - 3 * Da / (2 * u * dx)\n",
        "\n",
        "                ##\n",
        "                R1 = ((beta * alpha) / gamma)\n",
        "                R2 = ((2 * Da / (u * dx)) / gamma)\n",
        "                R3 = ((Da / (2 * u * dx)) / gamma)\n",
        "                ##\n",
        "\n",
        "                # Calcualte the BC effects:\n",
        "                j = start[i]\n",
        "                # print('j:', j)\n",
        "                c_BC[i] = R1 * C_IN_A - R2 * c[j] + R3 * c[j+1] # the boundary concentration for that node\n",
        "                c_BC[B + i] = R1 * C_IN_B - R2 * c[B+j] + R3 * c[B+j+1]\n",
        "            # print('c_BC:\\n', c_BC)\n",
        "            # print('c_BC.shape:\\n', c_BC.shape)\n",
        "\n",
        "            for k in range(len(start)):\n",
        "                vec_add[start[k]]  = get_X(t,coef_0,k)*c_BC[k]\n",
        "                vec_add[B + start[k]]  = get_X(t,coef_0,k)*c_BC[B+ k]\n",
        "\n",
        "            return vec_add\n",
        "            # print('np.shape(vect_add)\\n',np.shape(vec_add(nx, c, start)))\n",
        "        return final_matrix, vector_add(nx, c, start_CUP)\n",
        "\n",
        "    # ###########################################################################################\n",
        "\n",
        "    # # mod1: UNCOUPLED ISOTHERM:\n",
        "    # # Profiles for each component can be solved independently\n",
        "\n",
        "    # ###########################################################################################\n",
        "    def mod1(t, v, comp_idx, Q_pulse_all):\n",
        "        # call.append(\"call\")\n",
        "        # print(len(call))\n",
        "        c = v[:nx]\n",
        "        q = v[nx:]\n",
        "\n",
        "        # Initialize the derivatives\n",
        "        dc_dt = np.zeros_like(c)\n",
        "        dq_dt = np.zeros_like(q)\n",
        "        # print('v size\\n',np.shape(v))\n",
        "\n",
        "        # Isotherm:\n",
        "        #########################################################################\n",
        "        isotherm = iso_lin(theta_lin[comp_idx], c)\n",
        "        #isotherm = iso_langmuir(theta_lang[comp_idx], c, comp_idx)\n",
        "        #isotherm = iso_freundlich(theta_fre, c)\n",
        "\n",
        "\n",
        "        # Mass Transfer:\n",
        "        #########################################################################\n",
        "        # print('isotherm size\\n',np.shape(isotherm))\n",
        "        MT = mass_transfer(kav_params[comp_idx], isotherm, q)\n",
        "        #print('MT:\\n', MT)\n",
        "\n",
        "        coeff_matrix, vec_add = coeff_matrix_builder_UNC(t, Q_col_all, Q_pulse_all, dx, start, alpha, c, nx_col, comp_idx)\n",
        "        # print('coeff_matrix:\\n',coeff_matrix)\n",
        "        # print('vec_add:\\n',vec_add)\n",
        "        dc_dt = coeff_matrix @ c + vec_add - F * MT\n",
        "        dq_dt = MT\n",
        "\n",
        "        return np.concatenate([dc_dt, dq_dt])\n",
        "\n",
        "    # ##################################################################################\n",
        "\n",
        "    def mod2(t, v):\n",
        "\n",
        "        # where, v = [c, q]\n",
        "        c = v[:num_comp*nx] # c = [cA, cB] | cA = c[:nx], cB = c[nx:]\n",
        "        q = v[num_comp*nx:] # q = [qA, qB]| qA = q[:nx], qB = q[nx:]\n",
        "\n",
        "        # Craate Lables so that we know the component assignement in the c vecotor:\n",
        "        A, B = 0*nx, 1*nx # Assume Binary 2*nx, 3*nx, 4*nx, 5*nx\n",
        "        IDX = [A, B]\n",
        "\n",
        "        # Thus to refer to the liquid concentration of the i = nth row of component B: c[C + n]\n",
        "        # Or the the solid concentration 10th row of component B: q[B + 10]\n",
        "        # Or to refer to all A's OR B's liquid concentrations: c[A + 0: A + nx] OR c[B + 0: B + nx]\n",
        "\n",
        "\n",
        "        # Initialize the derivatives\n",
        "        dc_dt = np.zeros_like(c)\n",
        "        dq_dt = np.zeros_like(q)\n",
        "\n",
        "\n",
        "        coeff_matrix, vec_add = coeff_matrix_builder_CUP(t, Q_col_all, Q_pulse_all, dx, start, alpha, c, nx_col, IDX)\n",
        "        # print('coeff_matrix:\\n',coeff_matrix)\n",
        "        # print('vec_add:\\n',vec_add)\n",
        "\n",
        "\n",
        "\n",
        "        ####################### Building MT Terms ####################################################################\n",
        "\n",
        "        # Initialize\n",
        "\n",
        "        MT = np.zeros(len(c)) # column vector: MT kinetcis for each comp: MT = [MT_A MT_B]\n",
        "\n",
        "        for comp_idx in range(num_comp): # for each component\n",
        "\n",
        "            ######################(i) Isotherm ####################################################################\n",
        "\n",
        "            # Comment as necessary for required isotherm:\n",
        "            # isotherm = iso_bi_langmuir(theta_blang[comp_idx], c, IDX, comp_idx)\n",
        "            isotherm = iso_cup_langmuir(theta_cup_lang, c, IDX, comp_idx)\n",
        "            # print('qstar:\\n', isotherm.shape)\n",
        "            ################### (ii) MT ##########################################################\n",
        "            MT_comp = mass_transfer(kav_params[comp_idx], isotherm, q[IDX[comp_idx] + 0: IDX[comp_idx] + nx ])\n",
        "            MT[IDX[comp_idx] + 0: IDX[comp_idx] + nx ] = MT_comp\n",
        "            # [MT_A, MT_B, . . . ] KINETICS FOR EACH COMP\n",
        "\n",
        "\n",
        "\n",
        "        dc_dt = coeff_matrix @ c + vec_add - F * MT\n",
        "        dq_dt = MT\n",
        "\n",
        "        return np.concatenate([dc_dt, dq_dt])\n",
        "\n",
        "    # ##################################################################################\n",
        "\n",
        "    # SOLVING THE ODES\n",
        "    # creat storage spaces:\n",
        "    y_matrices = []\n",
        "\n",
        "    t_sets = []\n",
        "    t_lengths = []\n",
        "\n",
        "    c_IN_values_all = []\n",
        "    F_in_values_all = []\n",
        "    call = []\n",
        "\n",
        "    # print('----------------------------------------------------------------')\n",
        "    # print(\"\\n\\nSolving the ODEs. . . .\")\n",
        "\n",
        "\n",
        "\n",
        "    if iso_type == \"UNC\": # UNCOUPLED - solve 1 comp at a time\n",
        "        for comp_idx in range(num_comp): # for each component\n",
        "            # print(f'Solving comp {comp_idx}. . . .')\n",
        "            # print('\\nSolution Size:')\n",
        "            v0 = np.zeros(Ncol_num* (nx_col + nx_col)) #  for both c and q\n",
        "            solution = solve_ivp(mod1, t_span, v0, args=(comp_idx , Q_pulse_all))\n",
        "            y_solution, t = solution.y, solution.t\n",
        "            y_matrices.append(y_solution)\n",
        "            t_sets.append(t)\n",
        "            t_lengths.append(len(t))\n",
        "            # print(f'y_matrices[{i}]', y_matrices[i].shape)\n",
        "\n",
        "\n",
        "    # Assuming only a binary coupled system\n",
        "    if iso_type == \"CUP\": # COUPLED - solve\n",
        "            # nx = nx_col*num_comp\n",
        "            v0 = np.zeros(num_comp*(nx)*2) # for c and 2, for each comp\n",
        "            solution = solve_ivp(mod2, t_span, v0)\n",
        "            y_solution, t = solution.y, solution.t\n",
        "            # Convert y_solution from: [cA, cB, qA, qB] ,  TO: [[cA, qA ], [cB, qB]]\n",
        "            # Write a function to do that\n",
        "\n",
        "            def reshape_ysol(x, nx, num_comp):\n",
        "                # Initialize a list to store the reshaped components\n",
        "                reshaped_list = []\n",
        "\n",
        "                # Iterate over the number of components\n",
        "                for i in range(num_comp):\n",
        "                    # Extract cX and qX submatrices for the i-th component\n",
        "                    cX = x[i*nx:(i+1)*nx, :]      # Extract cX submatrix\n",
        "                    qX = x[i*nx + num_comp*nx : (i+1)*nx + num_comp*nx, :]       # Extract qX submatrix\n",
        "                    concat = np.concatenate([cX, qX])\n",
        "                    # print('i:', i)\n",
        "                    # print('cX:\\n',cX)\n",
        "                    # print('qX:\\n',qX)\n",
        "                    # Append the reshaped pair [cX, qX] to the list\n",
        "                    reshaped_list.append(concat)\n",
        "\n",
        "                # Convert the list to a NumPy array\n",
        "                result = np.array(reshaped_list)\n",
        "\n",
        "                return result\n",
        "\n",
        "            y_matrices = reshape_ysol(y_solution, nx, num_comp)\n",
        "            # print('len(t_sets) = ', len(t_sets[0]))\n",
        "            # print('len(t) = ', len(t))\n",
        "\n",
        "    # print('----------------------------------------------------------------')\n",
        "    # print('\\nSolution Size:')\n",
        "    # for i in range(num_comp):\n",
        "    #     print(f'y_matrices[{i}]', y_matrices[i].shape)\n",
        "    # print('----------------------------------------------------------------')\n",
        "    # print('----------------------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # ###########################################################################################\n",
        "\n",
        "    # VISUALIZATION\n",
        "\n",
        "    ###########################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # MASS BALANCE AND PURITY CURVES\n",
        "    ###########################################################################################\n",
        "\n",
        "    def find_indices(t_ode_times, t_schedule):\n",
        "        \"\"\"\n",
        "        t_schedule -> vector of times when (events) port switches happen e.g. at [0,5,10] seconds\n",
        "        t_ode_times -> vector of times from ODE\n",
        "\n",
        "        We want to know where in t_ode_times, t_schedule occures\n",
        "        These iwll be stored as indecies in t_idx\n",
        "        Returns:np.ndarray: An array of indices in t_ode_times corresponding to each value in t_schedule.\n",
        "        \"\"\"\n",
        "        t_idx = np.searchsorted(t_ode_times, t_schedule)\n",
        "        t_idx = np.append(t_idx, len(t_ode_times))\n",
        "\n",
        "        return t_idx\n",
        "\n",
        "    # Fucntion to find the values of scheduled quantities\n",
        "    # at all t_ode_times points\n",
        "\n",
        "    def get_all_values(X, t_ode_times, t_schedule_times, Name):\n",
        "\n",
        "        \"\"\"\n",
        "        X -> Matrix of Quantity at each schedule time. e.g:\n",
        "        At t_schedule_times = [0,5,10] seconds feed:\n",
        "        a concentraction of, X = [1,2,3] g/m^3\n",
        "\n",
        "        \"\"\"\n",
        "        # Get index times\n",
        "        t_idx = find_indices(t_ode_times, t_schedule_times)\n",
        "        # print('t_idx:\\n', t_idx)\n",
        "\n",
        "        # Initialize:\n",
        "        nrows = np.shape(X)[0]\n",
        "        # print('nrows', nrows)\n",
        "\n",
        "        values = np.zeros((nrows, len(t_ode_times))) # same num of rows, we just extend the times\n",
        "        # print('np.shape(values):\\n',np.shape(values))\n",
        "\n",
        "        # Modify:\n",
        "        k = 0\n",
        "\n",
        "        for i in range(len(t_idx)-1): # during each schedule interval\n",
        "            j = i%nrows\n",
        "\n",
        "            # # k is a counter that pushes the row index to the RHS every time it loops back up\n",
        "            # if j == 0 and i == 0:\n",
        "            #     pass\n",
        "            # elif j == 0:\n",
        "            #     k += 1\n",
        "\n",
        "            # print('j',j)\n",
        "\n",
        "            X_new = np.tile(X[:,j], (len(t_ode_times[t_idx[i]:t_idx[i+1]]), 1))\n",
        "\n",
        "            values[:, t_idx[i]:t_idx[i+1]] = X_new.T # apply appropriate quantity value at approprite time intrval\n",
        "\n",
        "        # Visualize:\n",
        "        # # Table\n",
        "        # print(Name,\" Values.shape:\\n\", np.shape(values))\n",
        "        # print(Name,\" Values:\\n\", values)\n",
        "        # # Plot\n",
        "        # plt.plot(t_ode_times, values)\n",
        "        # plt.xlabel('Time (s)')\n",
        "        # plt.ylabel('X')\n",
        "        # plt.show()\n",
        "\n",
        "        return values, t_idx\n",
        "\n",
        "\n",
        "    # Function that adds row slices from a matrix M into one vector\n",
        "    def get_X_row(M, row_start, jump, width):\n",
        "\n",
        "        \"\"\"\n",
        "        M  => Matrix whos rows are to be searched and sliced\n",
        "        row_start => Starting row - the row that the 1st slice comes from\n",
        "        jump => How far the row index jumps to caputre the next slice\n",
        "        width => the widths of each slice e.g. slice 1 is M[row, width[0]:width[1]]\n",
        "\n",
        "        \"\"\"\n",
        "        # Quick look at the inpiuts\n",
        "        # print('M.shape:\\n', M.shape)\n",
        "        # print('width:', width)\n",
        "\n",
        "        # Initialize\n",
        "        values = []\n",
        "        nrows = M.shape[0]\n",
        "\n",
        "        for i in range(len(width)-1):\n",
        "            j = i%nrows\n",
        "            # print('i', i)\n",
        "            # print('j', j)\n",
        "            t_start = int(width[i])\n",
        "            tend = int(width[i+1])\n",
        "\n",
        "            kk = (row_start+j*jump)%nrows\n",
        "\n",
        "            MM = M[kk, t_start:tend]\n",
        "\n",
        "            values.extend(MM)\n",
        "\n",
        "        return values\n",
        "\n",
        "\n",
        "\n",
        "    #  MASS INTO SYSMEM\n",
        "\n",
        "    # - Only the feed port allows material to FLOW IN\n",
        "    ###########################################################################################\n",
        "\n",
        "    # Convert the Feed concentration schedule to show feed conc for all time\n",
        "    # Do this for each component\n",
        "    # C_feed_all = [[] for _ in range(num_comp)]\n",
        "\n",
        "    row_start = 0 # iniital feed port row in schedule matrix\n",
        "\n",
        "    row_start_matrix_raff = nx_col*Z3\n",
        "    row_start_matrix_ext = (nx_col*(Z3 + Z4 + Z1))\n",
        "\n",
        "    row_start_schedule_raff = row_start+Z3\n",
        "    row_start_schedule_ext = row_start+Z3+Z4+Z1\n",
        "\n",
        "    jump_schedule = 1\n",
        "    jump_matrix = nx_col\n",
        "\n",
        "\n",
        "    def feed_profile(t_odes, Cj_pulse_all, t_schedule, row_start, jump):\n",
        "\n",
        "        \"\"\"\"\n",
        "        Function that returns :\n",
        "        (i) The total mass fed of each component\n",
        "        (ii) Vector of feed conc profiles of each component\n",
        "        \"\"\"\n",
        "\n",
        "        # Storage Locations:\n",
        "        C_feed_all = []\n",
        "        t_idx_all = []\n",
        "        m_feed = []\n",
        "\n",
        "        C_feed = [[] for _ in range(num_comp)]\n",
        "\n",
        "        for i in range(num_comp):\n",
        "\n",
        "            if iso_type == 'UNC':\n",
        "\n",
        "                C, t_idx = get_all_values(Cj_pulse_all[i], t_odes[i], t_schedule, 'Concentration')\n",
        "                t_idx_all.append(t_idx)\n",
        "\n",
        "            elif iso_type == 'CUP':\n",
        "                C, t_idx_all = get_all_values(Cj_pulse_all[i], t_odes, t_schedule, 'Concentration')\n",
        "\n",
        "            C_feed_all.append(C)\n",
        "\n",
        "            # print('t_idx_all:\\n', t_idx_all )\n",
        "\n",
        "        for i in range(num_comp):\n",
        "            if iso_type == 'UNC':\n",
        "                C_feed[i] = get_X_row( C_feed_all[i], row_start, jump, t_idx_all[i]) # g/cm^3\n",
        "            elif iso_type == 'CUP':\n",
        "                C_feed[i] = get_X_row( C_feed_all[i], row_start, jump, t_idx_all) # g/cm^3\n",
        "        # print('C_feed[0]:',C_feed[0])\n",
        "\n",
        "        for i in range(num_comp):\n",
        "            F_feed = np.array([C_feed[i]]) * QF # (g/cm^3 * cm^3/s)  =>  g/s | mass flow into col (for comp, i)\n",
        "            F_feed = np.array([F_feed]) # g/s\n",
        "\n",
        "            if iso_type == 'UNC':\n",
        "                m_feed_add = integrate.simpson(F_feed, x=t_odes[i]) # g\n",
        "            if iso_type == 'CUP':\n",
        "                m_feed_add = integrate.simpson(F_feed, x=t_odes) # g\n",
        "\n",
        "            m_feed.append(m_feed_add)\n",
        "\n",
        "        m_feed = np.concatenate(m_feed) # g\n",
        "        # print(f'm_feed: {m_feed} g')\n",
        "\n",
        "        return C_feed, m_feed, t_idx_all\n",
        "\n",
        "    if iso_type == 'UNC':\n",
        "        C_feed, m_feed, t_idx_all = feed_profile(t_sets, Cj_pulse_all, t_schedule, row_start, jump_schedule)\n",
        "    elif iso_type == 'CUP':\n",
        "        C_feed, m_feed, t_idx_all = feed_profile(t, Cj_pulse_all, t_schedule, row_start, jump_schedule)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def prod_profile(t_odes, y_odes, t_schedule, row_start_matrix, jump_matrix, t_idx_all, row_start_schedule):\n",
        "\n",
        "        \"\"\"\"\n",
        "        Function that can be used to return:\n",
        "\n",
        "        (i) The total mass exited at the Raffinate or Extract ports of each component\n",
        "        (ii) Vector of Raffinate or Extract mass flow profiles of each component\n",
        "        (iii) Vector of Raffinate or Extract vol flow profiles of each component\n",
        "\n",
        "        P = Product either raff or ext\n",
        "        \"\"\"\n",
        "        ######## Storages for the Raffinate #########\n",
        "        C_P1 = []\n",
        "        C_P2 = []\n",
        "\n",
        "        Q_all_flows = [] # Flowrates expirenced by each component\n",
        "        m_out_P = np.zeros(num_comp)\n",
        "\n",
        "        P_vflows_1 = []\n",
        "        P_mflows_1 = []\n",
        "        m_P_1 = []\n",
        "\n",
        "        P_vflows_2 = []\n",
        "        P_mflows_2 = []\n",
        "        m_P_2 = []\n",
        "        t_idx_all_Q = []\n",
        "\n",
        "        P_mprofile = []\n",
        "        P_cprofile = []\n",
        "        P_vflow = [[] for _ in range(num_comp)]\n",
        "\n",
        "\n",
        "        if iso_type == 'UNC':\n",
        "            for i in range(num_comp): # for each component\n",
        "                Q_all_flows_add, b = get_all_values(Q_col_all, t_odes[i], t_schedule, 'Column Flowrates')\n",
        "                # print('Q_all_flows_add:\\n', Q_all_flows_add)\n",
        "                Q_all_flows.append(Q_all_flows_add) # cm^3/s\n",
        "                t_idx_all_Q.append(b)\n",
        "\n",
        "        elif iso_type == 'CUP':\n",
        "            Q_all_flows, t_idx_all_Q = get_all_values(Q_col_all, t_odes, t_schedule, 'Column Flowrates')\n",
        "\n",
        "\n",
        "\n",
        "        for i in range(num_comp):# for each component\n",
        "\n",
        "            # Search the ODE matrix\n",
        "            C_R1_add = np.array(get_X_row( y_odes[i][:nx,:], row_start_matrix-1, jump_matrix, t_idx_all[i])) # exclude q\n",
        "            C_R2_add = np.array(get_X_row( y_odes[i][:nx,:], row_start_matrix, jump_matrix, t_idx_all[i]))\n",
        "            # Search the Flowrate Schedule\n",
        "            P_vflows_1_add = np.array(get_X_row(Q_all_flows[i], row_start_schedule-1, jump_schedule, t_idx_all_Q[i]))\n",
        "            P_vflows_2_add = np.array(get_X_row(Q_all_flows[i], row_start_schedule, jump_schedule, t_idx_all_Q[i]))\n",
        "\n",
        "            # Raffinate Massflow Curves\n",
        "            # print('C_R1_add.type():\\n',type(C_R1_add))\n",
        "            # print('np.shape(C_R1_add):\\n', np.shape(C_R1_add))\n",
        "\n",
        "            # print('P_vflows_1_add.type():\\n',type(P_vflows_1_add))\n",
        "            # print('np.shape(P_vflows_1_add):\\n', np.shape(P_vflows_1_add))\n",
        "\n",
        "            # Assuming only conc change accross port when (i) adding feed or (ii) desorbent\n",
        "            C_R2_add = C_R1_add\n",
        "            # P_mflows_1_add = C_R1_add * P_vflows_1_add  # (g/cm^3 * cm^3/s)  =>  g/s\n",
        "            # P_mflows_2_add = C_R2_add * P_vflows_2_add  # g/s\n",
        "\n",
        "            if row_start_matrix == row_start_matrix_raff:\n",
        "                P_vflows_1_add = -QR*np.ones_like(C_R1_add)\n",
        "                P_mflows_1_add = C_R1_add * P_vflows_1_add  # (g/cm^3 * cm^3/s)  =>  g/s\n",
        "\n",
        "            elif row_start_matrix == row_start_matrix_ext:\n",
        "                P_vflows_1_add = -QX*np.ones_like(C_R1_add)\n",
        "                P_mflows_1_add = C_R1_add * P_vflows_1_add  # (g/cm^3 * cm^3/s)  =>  g/s\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Flow profiles:\n",
        "            # Concentration\n",
        "            P_cprofile.append(C_R1_add) # g/s\n",
        "            # Mass g/s\n",
        "            P_mprofile.append(P_mflows_1_add ) #- P_mflows_2_add) # g/s\n",
        "            # Volumetric cm^3/s\n",
        "            P_vflow[i] = P_vflows_1_add #- P_vflows_2_add # cm^3\n",
        "\n",
        "            # Integrate\n",
        "            if iso_type == 'UNC':\n",
        "                m_P_add_1 = integrate.simpson(P_mflows_1_add, x=t_odes[i]) # g\n",
        "                # m_P_add_2 = integrate.simpson(P_mflows_2_add, x=t_odes[i]) # g\n",
        "\n",
        "            if iso_type == 'CUP':\n",
        "                m_P_add_1 = integrate.simpson(P_mflows_1_add, x=t_odes) # g\n",
        "                # m_P_add_2 = integrate.simpson(P_mflows_2_add, x=t_odes) # g\n",
        "\n",
        "\n",
        "\n",
        "            # Storage\n",
        "            C_P1.append(C_R1_add)  # Concentration Profiles\n",
        "            C_P2.append(C_R2_add)\n",
        "\n",
        "            P_vflows_1.append(P_vflows_1_add)\n",
        "            P_vflows_2.append(P_vflows_2_add)\n",
        "\n",
        "            P_mflows_1.append(P_mflows_1_add)\n",
        "            # P_mflows_2.append(P_mflows_2_add)\n",
        "\n",
        "            m_P_1.append(m_P_add_1) # masses of each component\n",
        "            # m_P_2.append(m_P_add_2) # masses of each component\n",
        "\n",
        "        # Final Mass Exited\n",
        "        # Mass out from P and ext\n",
        "        for i in range(num_comp):\n",
        "            m_out_P_add = m_P_1[i] #- m_P_2[i]\n",
        "            # print(f'i:{i}')\n",
        "            # print(f'm_out_P_add = m_P_1[i] - m_P_2[i]: { m_P_1[i]} - {m_P_2[i]}')\n",
        "            m_out_P[i] = m_out_P_add # [A, B] g\n",
        "\n",
        "        return P_cprofile, P_mprofile, m_out_P, P_vflow\n",
        "\n",
        "\n",
        "\n",
        "    # Evaluating the product flowrates\n",
        "    #######################################################\n",
        "    # raff_mprofile, m_out_raff, raff_vflow = prod_profile(t_sets, y_matrices, t_schedule, row_start_R1, row_start_R2, jump_matrix, t_idx_all, row_start+Z3)\n",
        "    # ext_mprofile, m_out_ext, ext_vflow = prod_profile(t_sets, y_matrices, t_schedule, row_start_X1, row_start_X2, jump_matrix, t_idx_all, row_start+Z3+Z4+Z1)\n",
        "    if iso_type == 'UNC':\n",
        "        raff_cprofile, raff_mprofile, m_out_raff, raff_vflow = prod_profile(t_sets, y_matrices, t_schedule, row_start_matrix_raff, jump_matrix, t_idx_all, row_start_schedule_raff)\n",
        "        ext_cprofile, ext_mprofile, m_out_ext, ext_vflow = prod_profile(t_sets, y_matrices, t_schedule, row_start_matrix_ext, jump_matrix, t_idx_all, row_start_schedule_ext)\n",
        "    elif iso_type == 'CUP':\n",
        "        raff_cprofile, raff_mprofile, m_out_raff, raff_vflow = prod_profile(t, y_matrices, t_schedule, row_start_matrix_raff, jump_matrix, t_idx_all, row_start_schedule_raff)\n",
        "        ext_cprofile, ext_mprofile, m_out_ext, ext_vflow = prod_profile(t, y_matrices, t_schedule, row_start_matrix_ext, jump_matrix, t_idx_all, row_start_schedule_ext)\n",
        "    #######################################################\n",
        "    # print(f'raff_vflow: {raff_vflow}')\n",
        "    # print(f'np.shape(raff_vflow): {np.shape(raff_vflow[0])}')\n",
        "    # print(f'ext_vflow: {ext_vflow}')\n",
        "    # print(f'np.shape(ext_vflow): {np.shape(ext_vflow[0])}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # MASS BALANCE:\n",
        "    #######################################################\n",
        "\n",
        "    # Error = Expected Accumulation - Model Accumulation\n",
        "\n",
        "    #######################################################\n",
        "\n",
        "    # Expected Accumulation = Mass In - Mass Out\n",
        "    # Model Accumulation = Integral in all col at tend (how much is left in col at end of sim)\n",
        "\n",
        "\n",
        "    # Calculate Expected Accumulation\n",
        "    #######################################################\n",
        "    m_out = np.array([m_out_raff]) + np.array([m_out_ext]) # g\n",
        "    m_out = np.concatenate(m_out)\n",
        "    m_in = np.concatenate(m_feed) # g\n",
        "    # ------------------------------------------\n",
        "    Expected_Acc = m_in - m_out # g\n",
        "    # ------------------------------------------\n",
        "\n",
        "\n",
        "    # Calculate Model Accumulation\n",
        "    #######################################################\n",
        "    def model_acc(y_ode, V_col_total, e, num_comp):\n",
        "        \"\"\"\n",
        "        Func to integrate the concentration profiles at tend and estimate the amount\n",
        "        of solute left on the solid and liquid phases\n",
        "        \"\"\"\n",
        "        mass_l = np.zeros(num_comp)\n",
        "        mass_r = np.zeros(num_comp)\n",
        "\n",
        "        for i in range(num_comp): # for each component\n",
        "\n",
        "            V_l = e * V_col_total # Liquid Volume cm^3\n",
        "            V_r = (1-e)* V_col_total # resin Volume cm^3\n",
        "\n",
        "            # conc => g/cm^3\n",
        "            # V => cm^3\n",
        "            # integrate to get => g\n",
        "\n",
        "            # # METHOD 1:\n",
        "            # V_l = np.linspace(0,V_l,nx) # cm^3\n",
        "            # V_r = np.linspace(0,V_r,nx) # cm^3\n",
        "            # mass_l[i] = integrate.simpson(y_ode[i][:nx,-1], x=x)*A_col*e # mass in liq at t=tend\n",
        "            # mass_r[i] = integrate.simpson(y_ode[i][nx:,-1], x=x)*A_col*(1-e) # mass in resin at t=tend\n",
        "\n",
        "            # METHOD 2:\n",
        "            V_l = np.linspace(0,V_l,nx) # cm^3\n",
        "            V_r = np.linspace(0,V_r,nx) # cm^3\n",
        "\n",
        "            mass_l[i] = integrate.simpson(y_ode[i][:nx,-1], x=V_l) # mass in liq at t=tend\n",
        "            mass_r[i] = integrate.simpson(y_ode[i][nx:,-1], x=V_r) # mass in resin at t=tend\n",
        "\n",
        "            # METHOD 3:\n",
        "            # c_avg[i] = np.average(y_ode[i][:nx,-1]) # Average conc at t=tend\n",
        "            # q_avg[i] = np.average(y_ode[i][:nx,-1])\n",
        "\n",
        "            # mass_l = c_avg * V_l\n",
        "            # mass_r = q_avg * V_r\n",
        "\n",
        "\n",
        "        Model_Acc = mass_l + mass_r # g\n",
        "\n",
        "        return Model_Acc\n",
        "\n",
        "    Model_Acc = model_acc(y_matrices, V_col_total, e, num_comp)\n",
        "\n",
        "    # ------------------------------------------\n",
        "    Error = Model_Acc - Expected_Acc\n",
        "\n",
        "    Error_percent = (sum(Error)/sum(Expected_Acc))*100\n",
        "    # ------------------------------------------\n",
        "\n",
        "    # Calculate KEY PERORMANCE PARAMETERS:\n",
        "    #######################################################\n",
        "    # 1. Purity\n",
        "    # 2. Recovery\n",
        "    # 3. Productivity\n",
        "\n",
        "\n",
        "    # 1. Purity\n",
        "    #######################################################\n",
        "    # 1.1 Instantanoues:\n",
        "    # raff_in_purity = raff_mprofile/sum(raff_mprofile)\n",
        "    # ext_insant_purity = ext_mprofile/sum(ext_mprofile)\n",
        "\n",
        "    # 1.2 Integral:\n",
        "    raff_intgral_purity = m_out_raff/sum(m_out_raff)*100\n",
        "    ext_intgral_purity = m_out_ext/sum(m_out_ext)*100\n",
        "\n",
        "    # Final Attained Purity in the Stream\n",
        "    raff_stream_final_purity = np.zeros(num_comp)\n",
        "    ext_stream_final_purity = np.zeros(num_comp)\n",
        "\n",
        "    for i in range(num_comp):\n",
        "        raff_stream_final_purity[i] = raff_cprofile[i][-1]\n",
        "        ext_stream_final_purity[i] = ext_cprofile[i][-1]\n",
        "\n",
        "\n",
        "\n",
        "    # 2. Recovery\n",
        "    #######################################################\n",
        "    # 2.1 Instantanoues:\n",
        "\n",
        "    # raff_in_recovery = raff_mprofile/sum(C_feed*QF)\n",
        "    # ext_insant_recovery = ext_mprofile/sum(C_feed*QF)\n",
        "\n",
        "    # 2.2 Integral:\n",
        "    raff_recov = m_out_raff/m_in*100\n",
        "    ext_recov = m_out_ext/m_in*100\n",
        "\n",
        "    # 3. Productivity\n",
        "    #######################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Visuliization of PERORMANCE PARAMETERS:\n",
        "    #######################################################\n",
        "\n",
        "    ############## TABLES ##################\n",
        "\n",
        "\n",
        "\n",
        "    # Define the data for the table\n",
        "    # data = {\n",
        "    #     'Metric': [\n",
        "    #         'Total Mass IN',\n",
        "    #         'Total Mass OUT',\n",
        "    #         'Total Expected Acc (IN-OUT)',\n",
        "    #         'Total Model Acc (r+l)',\n",
        "    #         'Total Error (Mod-Exp)',\n",
        "    #         'Total Error Percent (relative to Exp_Acc)',\n",
        "    #         'Final Raffinate Collected Purity [A, B,. . ]',\n",
        "    #         'Final Extract Collected Purity [A, B,. . ]',\n",
        "    #         'Final Raffinate Dimensionless Stream Concentration  [A, B,. . ]',\n",
        "    #         'Final Extract Dimensionless Stream Concentration  [A, B,. . ]',\n",
        "    #         'Final Raffinate Recovery[A, B,. . ]',\n",
        "    #         'Final Extract Recovery[A, B,. . ]'\n",
        "    #     ],\n",
        "    #     'Value': [\n",
        "    #         f\"{m_in} g\",\n",
        "    #         f\"{m_out} g\",\n",
        "    #         f'{sum(Expected_Acc)} g',\n",
        "    #         f'{sum(Model_Acc)} g',\n",
        "    #         f'{sum(Error)} g',\n",
        "    #         f'{Error_percent} %',\n",
        "\n",
        "    #         f'{raff_intgral_purity} %',\n",
        "    #         f'{ext_intgral_purity} %',\n",
        "    #         f'{raff_stream_final_purity} g/cm^3',\n",
        "    #         f'{ext_stream_final_purity}',\n",
        "    #         f'{raff_recov} %',\n",
        "    #         f'{ext_recov} %'\n",
        "    #     ]\n",
        "    # }\n",
        "\n",
        "    # # Create a DataFrame\n",
        "    # df = pd.DataFrame(data)\n",
        "\n",
        "    # # Display the DataFrame\n",
        "    # print(df)\n",
        "\n",
        "    return y_matrices, nx, t, t_sets, t_schedule, C_feed, m_in, m_out, raff_cprofile, ext_cprofile, raff_intgral_purity, raff_recov, ext_intgral_purity, ext_recov, raff_vflow, ext_vflow, Model_Acc, Expected_Acc, Error_percent\n",
        "\n"
      ],
      "metadata": {
        "id": "IUcyZ2DE0t85"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################\n",
        "# What tpye of isoherm is required?\n",
        "# Coupled: \"CUP\"\n",
        "# Uncoupled: \"UNC\"\n",
        "iso_type = \"UNC\"\n",
        "\n",
        "###################### PRIMARY INPUTS #########################\n",
        "# Define the names, colors, and parameter sets for 6 components\n",
        "Names = [\"Glucose\", \"Fructose\"]#, 'C', 'D']#, \"C\"]#, \"D\", \"E\", \"F\"]\n",
        "color = [\"g\", \"orange\"]#, \"purple\", \"brown\"]#, \"b\"]#, \"r\", \"purple\", \"brown\"]\n",
        "num_comp = len(Names) # Number of components\n",
        "e = 0.40         # bed voidage\n",
        "Pe_all = [500, 500] #, 200, 200]\n",
        "Bm = 300\n",
        "\n",
        "# Column Dimensions\n",
        "\n",
        "# How many columns in each Zone?\n",
        "\n",
        "Z1, Z2, Z3, Z4 = 1,3,3,1 # *3 for smb config\n",
        "zone_config = np.array([Z1, Z2, Z3, Z4])\n",
        "nnn = Z1 + Z2 + Z3 + Z4\n",
        "\n",
        "L = 70 # cm # Length of one column\n",
        "d_col = 5 # cm # column internal diameter\n",
        "# Calculate the radius\n",
        "r_col = d_col / 2\n",
        "# Calculate the area of the base\n",
        "A_col = np.pi * (r_col ** 2) # cm^2\n",
        "V_col = A_col*L # cm^3\n",
        "# Dimensions of the tubing and from each column:\n",
        "# Assuming the pipe diameter is 20% of the column diameter:\n",
        "d_in = 0.2 * d_col # cm\n",
        "nx_per_col = 15\n",
        "\n",
        "\n",
        "################ Time Specs #################################################################################\n",
        "t_index_min = 3.30 # min # Index time # How long the pulse holds before swtiching\n",
        "n_num_cycles = 15    # Number of Cycles you want the SMB to run for\n",
        "###############  FLOWRATES   #################################################################################\n",
        "\n",
        "# Jochen et al:\n",
        "Q_P, Q_Q, Q_R, Q_S = 5.21, 4, 5.67, 4.65 # x10-7 m^3/s\n",
        "conv_fac = 0.1 # x10-7 m^3/s => cm^3/s\n",
        "Q_P, Q_Q, Q_R, Q_S  = Q_P*conv_fac, Q_Q*conv_fac, Q_R*conv_fac, Q_S*conv_fac\n",
        "\n",
        "Q_I, Q_II, Q_III, Q_IV = Q_R,  Q_S, Q_P, Q_Q\n",
        "\n",
        "\n",
        "Q_internal = np.array([Q_I, Q_II, Q_III, Q_IV])\n",
        "\n",
        "\n",
        "\n",
        "# # Parameter Sets for different components\n",
        "################################################################\n",
        "\n",
        "# Units:\n",
        "# - Concentrations: g/cm^3\n",
        "# - kh: 1/s\n",
        "# - Da: cm^2/s\n",
        "\n",
        "# A must have a less affinity to resin that B - FOUND IN EXtract purity\n",
        "parameter_sets = [\n",
        "    {\"kh\": 3.15/100, \"H\": 0.27, \"C_feed\": 0.02},  # Component A\n",
        "    {\"kh\": 2.217/100, \"H\": 0.53, \"C_feed\": 0.02}] #, # Component B\n",
        "\n",
        "# ISOTHERM PARAMETERS\n",
        "###########################################################################################\n",
        "theta_lin = [parameter_sets[i]['H'] for i in range(num_comp)] # [HA, HB]\n",
        "print('theta_lin:', theta_lin)\n",
        "# theta_lang = [1, 2, 3, 4 ,5, 6] # [HA, HB]\n",
        "theta_cup_lang = [5.29, 3.24, 2.02, 0.03] # [HA, HB, KA, KB]\n",
        "# theta_fre = [1.2, 0.5]\n",
        "# theta_blang = [[2.69, 0.0336, 0.0466, 0.1, 1, 3],\n",
        "#                 [3.73, 0.0336, 0.0466, 0.3, 1, 3]] # [HA, HB]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0VTadDf01Dd",
        "outputId": "6d642881-9fa9-436c-d800-340fb0134a7a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "theta_lin: [0.27, 0.53]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization Settings"
      ],
      "metadata": {
        "id": "k9VGA_Q5h1eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - - - - -\n",
        "Q_fixed_feed = 2 # L/h\n",
        "Q_fixed_D = 2 # L/h\n",
        "# - - - - -\n",
        "t_index_min = 5 # min\n",
        "# - - - - -\n",
        "Q_max = 7 # L/h\n",
        "Q_min = 1 # L/h\n",
        "# - - - - -\n",
        "m_max = 0.53\n",
        "m_min = 0.27\n",
        "# - - - - -\n",
        "m1_fixed = 0.8\n",
        "m4_fixed = 0.2\n",
        "# - - - - -\n",
        "sampling_budget = 20\n",
        "optimization_budget = 50\n",
        "constraint_threshold = 0.995\n",
        "# - - - - -\n",
        "# L/h --> cm^3/s:\n",
        "Q_max = Q_max/3.6 # L/h --> cm^3/s\n",
        "Q_max = Q_min/3.6 # L/h --> cm^3/s\n",
        "Q_fixed_feed = Q_fixed_feed/3.6 # L/h --> cm^3/s\n",
        "Q_fixed_D = Q_fixed_D/3.6 # L/h --> cm^3/s\n",
        "\n",
        "# - - - - -"
      ],
      "metadata": {
        "id": "CpNHd2DGh0aK"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SMB_inputs = [iso_type, Names, color, num_comp, nx_per_col, e, Pe_all, Bm, zone_config, L, d_col, d_in, t_index_min, n_num_cycles, Q_internal, parameter_sets]\n"
      ],
      "metadata": {
        "id": "J-t9zQRu03se"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different Methods to Sample [m1, m2, m3, m4]"
      ],
      "metadata": {
        "id": "niwccMVzjayK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lhq_sample_mj(m_min, m_max, n_samples, diff=0.1):\n",
        "    \"\"\"\n",
        "    Function that performs Latin Hypercube (LHS) sampling for [m1, m2, m3, m4]\n",
        "    Note that for all mjs: (m_min < m_j < m_max)\n",
        "    And that:\n",
        "          (i)   m4 < m1 - (diff*m1) and m2 < m1 - (diff*m1)\n",
        "          (ii)  m2 < m3 - (diff*m3)\n",
        "          (iii) m3 > m4 + (diff*m4)\n",
        "    Final result is an np.array of size: (n_samples, 4)\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the array to store the samples\n",
        "    samples = np.zeros((n_samples, 4))\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        # Sample m1, m2, m3, m4 within bounds and respecting constraints\n",
        "        m1 = np.random.uniform(m_min, m_max)\n",
        "        m4 = np.random.uniform(m_min, m1-diff*m1)\n",
        "\n",
        "        # Sample m2 such that it respects the constraint: m2 < m1 - (diff*m1)\n",
        "        m2 = np.random.uniform(m_min, m_max)\n",
        "        while m2 >= m1 - (diff * m1):  # Ensuring m2 < m1 - (diff*m1)\n",
        "            m2 = np.random.uniform(m_min, m_max)\n",
        "\n",
        "        # Sample m3 such that it respects the constraint: m3 > m2 + (diff*m2)\n",
        "        m3 = np.random.uniform(m_min, m_max)\n",
        "        while m3 <= m2 + (diff * m2):  # Ensuring m3 > m2 + (diff*m2)\n",
        "            m3 = np.random.uniform(m_min, m_max)\n",
        "\n",
        "        # Ensure the constraint: m3 > m4 + (diff * m4)\n",
        "        while m3 <= m4 + (diff * m4):  # Ensuring m3 > m4 + (diff*m4)\n",
        "            m3 = np.random.uniform(m_min, m_max)\n",
        "\n",
        "        # Store the sample in the array\n",
        "        samples[i] = [m1, m2, m3, m4]\n",
        "\n",
        "\n",
        "    return samples\n",
        "\n",
        "def fixed_feed_lhq_sample_mj(t_index_min, Q_fixed_feed, m_min, m_max, n_samples, diff=0.1):\n",
        "    \"\"\"\n",
        "    Since the feed is fixed, m3 is caluclated\n",
        "\n",
        "    Function that performs Latin Hypercube (LHS) sampling for [m1, m2, m3, m4]\n",
        "    Note that for all mjs: (m_min < m_j < m_max)\n",
        "    And that:\n",
        "          (i)   m4 < m1 - (diff*m1) and m2 < m1 - (diff*m1)\n",
        "          (ii)  m2 < m3 - (diff*m3)\n",
        "          (iii) m3 > m4 + (diff*m4)\n",
        "    Final result is an np.array of size: (n_samples, 4)\n",
        "    \"\"\"\n",
        "    # Initialize the array to store the samples\n",
        "    samples = np.zeros((n_samples, 4))\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        # Sample m1, m2, m3, m4 within bounds and respecting constraints\n",
        "        m1 = np.random.uniform(m_min, m_max)\n",
        "        m4 = np.random.uniform(m_min, m1-diff*m1)\n",
        "\n",
        "        # Sample m2 such that it respects the constraint: m2 < m1 - (diff*m1)\n",
        "        m2 = np.random.uniform(m_min, m_max)\n",
        "        while m2 >= m1 - (diff * m1):  # Ensuring m2 < m1 - (diff*m1)\n",
        "            m2 = np.random.uniform(m_min, m_max)\n",
        "\n",
        "        # Sample m3 such that it respects the constraint: m3 > m2 + (diff*m2)\n",
        "        m3 = np.random.uniform(m_min, m_max)\n",
        "        while m3 <= m2 + (diff * m2):  # Ensuring m3 > m2 + (diff*m2)\n",
        "            m3 = np.random.uniform(m_min, m_max)\n",
        "\n",
        "        # Ensure the constraint: m3 > m4 + (diff * m4)\n",
        "        while m3 <= m4 + (diff * m4):  # Ensuring m3 > m4 + (diff*m4)\n",
        "            m3 = np.random.uniform(m_min, m_max)\n",
        "\n",
        "        # Store the sample in the array\n",
        "        samples[i] = [m1, m2, m3, m4]\n",
        "\n",
        "    return samples\n",
        "\n",
        "def fixed_m1_and_m4_lhq_sample_mj(t_index_min, m1, m4, m_min, m_max, n_samples, diff=0.1):\n",
        "    \"\"\"\n",
        "    - Since the feed is fixed, m3 is caluclated AND\n",
        "    - Since the desorbant is fixed, m1 is caluclated\n",
        "\n",
        "    Function that performs Latin Hypercube (LHS) sampling for [m1, m2, m3, m4]\n",
        "    Note that for all mjs: (m_min < m_j < m_max)\n",
        "    And that:\n",
        "          (i)   m4 < m1 - (diff*m1) and m2 < m1 - (diff*m1)\n",
        "          (ii)  m2 < m3 - (diff*m3)\n",
        "          (iii) m3 > m4 + (diff*m4)\n",
        "    Final result is an np.array of size: (n_samples, 4)\n",
        "    \"\"\"\n",
        "    # Initialize the array to store the samples\n",
        "    samples = np.zeros((n_samples, 4))\n",
        "    samples[:,0] = np.ones(n_samples)*m1\n",
        "    samples[:,-1] = np.ones(n_samples)*m4\n",
        "    # print(f'samples: {samples}')\n",
        "\n",
        "    m2_set = np.linspace(m_min, m_max, n_samples)\n",
        "    # print(f'm2_set: {m2_set}')\n",
        "    num_of_m3_per_m2 = 3\n",
        "    i = np.arange(n_samples)\n",
        "    k = np.repeat(i,num_of_m3_per_m2)\n",
        "\n",
        "    #Sample from the separation triangle:\n",
        "    for i in range(n_samples): # for each vertical line\n",
        "        # print(f'k: {k[i]}')\n",
        "        m2 = m2_set[k[i]]\n",
        "\n",
        "        samples[i, 1] = m2\n",
        "\n",
        "        if i == 0:\n",
        "          m3 = m_max\n",
        "          samples[i, 2] = m3 # apex of trianlge\n",
        "        else:\n",
        "          m3 = np.random.uniform(m2, m_max)\n",
        "          samples[i, 2] = m3\n",
        "\n",
        "    return samples"
      ],
      "metadata": {
        "id": "N0r7I1X-jhN5"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Generate Inital Data"
      ],
      "metadata": {
        "id": "G5V9UfAbjsxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the obj and constraint functions\n",
        "def obj_con(X, t_index_min):\n",
        "  \"\"\"Feasibility weighted objective; zero if not feasible.\n",
        "\n",
        "    X = [m1, m2, m3, m4]; type= torche_tensor\n",
        "    Objective: WAR = Weighted Average Recovery\n",
        "    Constraint: WAP = Weighted Average Purity\n",
        "\n",
        "    Use WAP to calculate the feasibility weights. Which\n",
        "    will scale teh EI output.\n",
        "\n",
        "  \"\"\"\n",
        "  X = np.array(X)\n",
        "  def mj_to_Qj(mj):\n",
        "    Qj = (mj*V_col*(1-e) + V_col*e)/(t_index_min*60) # cm^3/s\n",
        "    return Qj\n",
        "\n",
        "  # print(f'np.shape(x_new)[0]: {np.shape(X)}')\n",
        "  if X.ndim == 1:\n",
        "\n",
        "      Pur = np.zeros(2)\n",
        "      Rec = np.zeros(2)\n",
        "      # Unpack and convert to float and np.arrays from torch.tensors:\n",
        "      m1, m2, m3, m4 = float(X[0]), float(X[1]), float(X[2]), float(X[3])\n",
        "      print(f'[m1, m2, m3, m4]: [{m1}, {m2}, {m3}, {m4}]')\n",
        "      Q_I, Q_II, Q_III, Q_IV = mj_to_Qj(m1), mj_to_Qj(m2), mj_to_Qj(m3), mj_to_Qj(m4)\n",
        "      Q_internal = np.array([Q_I, Q_II, Q_III, Q_IV]) # cm^3/s\n",
        "      # print(f'Q_internal: {Q_internal} cm^s/s')\n",
        "      print(f'Q_internal: {Q_internal*3.6} L/h')\n",
        "      # print(f'Q_internal type: {type(Q_internal)}')\n",
        "\n",
        "      SMB_inputs[12] = t_index_min  # Update t_index\n",
        "      SMB_inputs[14] = Q_internal # Update Q_internal\n",
        "\n",
        "      results = SMB(SMB_inputs)\n",
        "\n",
        "      # print(f'done solving sample {i+1}')\n",
        "\n",
        "      raff_purity = results[10]  # [Glu, Fru]\n",
        "      ext_purity = results[12]  # [Glu, Fru]\n",
        "\n",
        "      raff_recovery = results[11]  # [Glu, Fru]\n",
        "      ext_recovery = results[13]  # [Glu, Fru]\n",
        "\n",
        "      pur1 = raff_purity[0] / 100\n",
        "      pur2 = ext_purity[1] / 100\n",
        "\n",
        "      rec1 = raff_recovery[0] / 100\n",
        "      rec2 = ext_recovery[1] / 100\n",
        "\n",
        "      # Pack\n",
        "      # WAP[i] = WAP_add\n",
        "      # WAR[i] = WAR_add\n",
        "      Pur[:] = [pur1, pur2]\n",
        "      Rec[:] = [rec1, rec2]\n",
        "  elif X.ndim > 1:\n",
        "      Pur = np.zeros((len(X[:,0]), 2))\n",
        "      Rec = np.zeros((len(X[:,0]), 2))\n",
        "\n",
        "      for i in range(len(X[:,0])):\n",
        "\n",
        "          # print(f't_index: {t_index}')\n",
        "          # print(f't_index type: {type(t_index)}')\n",
        "\n",
        "          if np.shape(X)[-1] == 4: # when we are generating the initial smaples (we have all the flowrates already)\n",
        "              # Unpack and convert to float and np.arrays from torch.tensors:\n",
        "              m1, m2, m3, m4 = float(X[i,0]), float(X[i,1]), float(X[i,2]), float(X[i,3])\n",
        "              print(f'[m1, m2, m3, m4]: [{m1}, {m2}, {m3}, {m4}]')\n",
        "              Q_I, Q_II, Q_III, Q_IV = mj_to_Qj(m1), mj_to_Qj(m2), mj_to_Qj(m3), mj_to_Qj(m4)\n",
        "              Q_internal = np.array([Q_I, Q_II, Q_III, Q_IV]) # cm^3/s\n",
        "              print(f'Q_internal: {Q_internal} cm^s/s')\n",
        "              print(f'Q_internal: {Q_internal*3.6} L/h')\n",
        "              print(f'Q_internal type: {type(Q_internal)}')\n",
        "\n",
        "          # elif np.shape(X)[-1] < 4: # During optimization - (we only have QX, Q_rec and t_index)\n",
        "          #     # Unpack and convert to float and np.arrays from torch.tensors:\n",
        "          #     print(f'-----------------')\n",
        "          #     print(f't_index: {t_index}')\n",
        "          #     # print(f't_index type: {type(t_index)}')\n",
        "          #     QX= float(X[i,0]) # cm^3/s\n",
        "          #     Q_rec = -float(X[i,1])# cm^3/s ENSURE this is negative value\n",
        "\n",
        "          #     # ----- Caclulate QR, using vol balance\n",
        "          #     vol_in = Q_fixed_feed + Q_fixed_D # cm^3/s\n",
        "          #     QR = -(vol_in + QX) # SINCE abs(vol_in) > abs(QX)\n",
        "\n",
        "          #     Q_external = np.array([Q_fixed_feed, QR, Q_fixed_D, QX])\n",
        "          # -------------------------------------------------------------\n",
        "          # -------------------------------------------------------------\n",
        "\n",
        "          # print(f'Q_internal type: {type(Q_internal)}')\n",
        "          # Update SMB_inputs:\n",
        "          SMB_inputs[12] = t_index_min  # Update t_index\n",
        "          SMB_inputs[14] = Q_internal # Update Q_internal\n",
        "\n",
        "          results = SMB(SMB_inputs)\n",
        "\n",
        "          # print(f'done solving sample {i+1}')\n",
        "\n",
        "          raff_purity = results[10]  # [Glu, Fru]\n",
        "          ext_purity = results[12]  # [Glu, Fru]\n",
        "\n",
        "          raff_recovery = results[11]  # [Glu, Fru]\n",
        "          ext_recovery = results[13]  # [Glu, Fru]\n",
        "\n",
        "          pur1 = raff_purity[0] / 100\n",
        "          pur2 = ext_purity[1] / 100\n",
        "\n",
        "          rec1 = raff_recovery[0] / 100\n",
        "          rec2 = ext_recovery[1] / 100\n",
        "\n",
        "          # Pack\n",
        "          # WAP[i] = WAP_add\n",
        "          # WAR[i] = WAR_add\n",
        "          Pur[i,:] = [pur1, pur2]\n",
        "          Rec[i,:] = [rec1, rec2]\n",
        "\n",
        "  return  Rec, Pur\n",
        "\n",
        "# ------ Generate Initial Data\n",
        "def generate_initial_data(sampling_budget, t_index_min):\n",
        "\n",
        "    # generate training data\n",
        "    # print(f'Getting {sampling_budget} Samples')\n",
        "    # train_x = lhq_sample_mj(0.2, 1.7, n, diff=0.1)\n",
        "    # train_x = fixed_feed_lhq_sample_mj(t_index_min, Q_fixed_feed, 0.2, 1.7, n, diff=0.1)\n",
        "    train_all = fixed_m1_and_m4_lhq_sample_mj(t_index_min, m1_fixed, m4_fixed, m_min, m_max, sampling_budget, diff=0.1)\n",
        "    # print(f'train_all: {train_all}')\n",
        "    # print(f'Done Getting {sampling_budget} Samples')\n",
        "\n",
        "    # exact_obj, exact_con = weighted_obj(train_x) # add output dimension\n",
        "    # print(f'Solving Over {sampling_budget} Samples')\n",
        "    Rec, Pur = obj_con(train_all, t_index_min)\n",
        "    # print(f'Done Getting {sampling_budget} Samples')\n",
        "    all_outputs = np.hstack((Rec, Pur))\n",
        "    return train_all, all_outputs"
      ],
      "metadata": {
        "id": "KHfU2oVHjwbP"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the generate_initial_data Function"
      ],
      "metadata": {
        "id": "WcsFD02pj3oK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_all, all_initial_inputs = generate_initial_data(2,t_index_min) # sampling_budget\n",
        "print(f'train_all{ train_all}')\n",
        "print(f'all_initial_inputs{ all_initial_inputs}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "8q5aQnZ4j1ev",
        "outputId": "805f6edb-5c6d-44b0-9220-8b1e53d4d356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'obj_con' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e802a5c1b866>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_initial_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_initial_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_index_min\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sampling_budget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'train_all{ train_all}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'all_initial_inputs{ all_initial_inputs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-8fa390a24875>\u001b[0m in \u001b[0;36mgenerate_initial_data\u001b[0;34m(sampling_budget, t_index_min)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# exact_obj, exact_con = weighted_obj(train_x) # add output dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# print(f'Solving Over {sampling_budget} Samples')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mRec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_con\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_index_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# print(f'Done Getting {sampling_budget} Samples')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mall_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'obj_con' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Setup\n",
        "\n",
        "\n",
        "First, we define the constraint used in the example in outcome_constraint. The second function weighted_obj is a \"feasibility-weighted objective,\" which returns zero when not feasible. Not that both the constraint and the objective function come from the same experiment."
      ],
      "metadata": {
        "id": "CCHRLIYT-2Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Surrogate model creation ---\n",
        "def surrogate_model(X_train, y_train):\n",
        "    X_train = np.atleast_2d(X_train)\n",
        "    y_train = np.atleast_1d(y_train)\n",
        "\n",
        "    if y_train.ndim == 2 and y_train.shape[1] == 1:\n",
        "        y_train = y_train.ravel()\n",
        "\n",
        "    # kernel = C(1.0, (1e-4, 10.0)) * RBF(1.0, (1e-4, 10.0))\n",
        "    kernel = Matern(length_scale=1.0, nu=1.5)\n",
        "\n",
        "    gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-5, normalize_y=True, n_restarts_optimizer=5)\n",
        "\n",
        "    gp.fit(X_train, y_train)\n",
        "\n",
        "    return gp\n",
        "\n",
        "# --- AQ funcs:\n",
        "\n",
        "# --- AQ func: Expected Constrained Improvement ---\n",
        "def log_expected_constrained_improvement(x, surrogate_obj_gp, constraint_gps, constraint_thresholds, y_best, xi=0.01):\n",
        "    x = np.asarray(x).reshape(1, -1)\n",
        "\n",
        "    mu_obj, sigma_obj = surrogate_obj_gp.predict(x, return_std=True)\n",
        "    # print(f'mu_obj: {mu_obj}, sigma_obj: {sigma_obj} ')\n",
        "\n",
        "\n",
        "    with np.errstate(divide='warn'):\n",
        "        Z = (y_best - mu_obj - xi) / sigma_obj\n",
        "        ei = (y_best - mu_obj - xi) * norm.cdf(Z) + sigma_obj * norm.pdf(Z)\n",
        "    # print(f'ei: {ei}')\n",
        "\n",
        "\n",
        "    # Calcualte the probability of Feasibility, \"prob_feas\"\n",
        "    prob_feas = 1.0 # initialize\n",
        "\n",
        "    for gp_c, lam in zip(constraint_gps, constraint_thresholds):\n",
        "\n",
        "        mu_c, sigma_c = gp_c.predict(x, return_std=True)\n",
        "\n",
        "        # lam -> inf = 1- (-inf -> lam)\n",
        "        prob_that_LESS_than_mu = norm.cdf((lam - mu_c) / sigma_c)\n",
        "\n",
        "        prob_that_GREATER_than_mu = 1 - prob_that_LESS_than_mu\n",
        "\n",
        "        pf = prob_that_GREATER_than_mu\n",
        "\n",
        "        # pf is a vector,\n",
        "        # We just want the non-zero part\n",
        "        pf = pf[pf != 0]\n",
        "        # Avoid empty sets:\n",
        "        if not pf:\n",
        "            pf = 1e-8\n",
        "\n",
        "\n",
        "        # print(f'pf: {pf}')\n",
        "\n",
        "        # if we assume that the condtions are independent,\n",
        "        # then we can \"multiply\" the weights to get the \"joint probability\" of feasility\n",
        "        prob_feas *= pf\n",
        "\n",
        "    # print(f'ei: {ei}')\n",
        "    # print(f'prob_feas: {prob_feas}')\n",
        "    log_eic = np.log(ei) + np.log(prob_feas)\n",
        "    # print(f'log_eic: {log_eic}')\n",
        "    # print(f'Convert to float')\n",
        "\n",
        "    log_eic = float(np.squeeze(log_eic))  # Convert to scalar\n",
        "    # print(f'log_eic: {log_eic}')\n",
        "    return -log_eic\n",
        "\n",
        "# 1. Expected Improvement ---\n",
        "def expected_improvement(x, surrogate_gp, y_best):\n",
        "    \"\"\"\n",
        "    Computes the Expected Improvement at a point x.\n",
        "    Scalarizes the surrogate predictions using Tchebycheff, then computes EI.\n",
        "\n",
        "    Note that the surrogate GP already has the weights applied to it\n",
        "    \"\"\"\n",
        "    x = np.array(x).reshape(1, -1)\n",
        "\n",
        "    mu, sigma = surrogate_gp.predict(x, return_std=True)\n",
        "\n",
        "    # print(f'mu: {mu}')\n",
        "    # print(f'y_best: {y_best}')\n",
        "    # Compute EI\n",
        "\n",
        "    xi = 0.2 # the greater the value of xi, the more we encourage exploration\n",
        "    with np.errstate(divide='warn'):\n",
        "        Z = (y_best - mu - xi) / sigma\n",
        "        ei = (y_best - mu - xi) * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
        "        ei[sigma == 0.0] = 0.0\n",
        "\n",
        "    return -ei[0]  # Negative for minimization\n",
        "\n",
        "    # 2. Probability of Imporovement:\n",
        "def probability_of_improvement(x, surrogate_gp, y_best, xi=0.005):\n",
        "    \"\"\"\n",
        "    Computes the Probability of Improvement (PI) acquisition function.\n",
        "\n",
        "    Parameters:\n",
        "    - mu: np.array of predicted means (shape: [n_samples])\n",
        "    - sigma: np.array of predicted std deviations (shape: [n_samples])\n",
        "    - best_f: scalar, best objective value observed so far\n",
        "    - xi: float, small value to balance exploration/exploitation (default: 0.01)\n",
        "\n",
        "    Returns:\n",
        "    - PI: np.array of probability of improvement values\n",
        "    \"\"\"\n",
        "    x = np.array(x).reshape(1, -1)\n",
        "\n",
        "    mu, sigma = surrogate_gp.predict(x, return_std=True)\n",
        "\n",
        "    # Avoid division by zero\n",
        "    if sigma == 0:\n",
        "      sigma = 1e-8\n",
        "\n",
        "    z = (y_best - mu - xi) / sigma\n",
        "\n",
        "    pi = 1 - norm.cdf(z)\n",
        "\n",
        "    return -pi\n",
        "\n",
        "# --- ParEGO Main Loop ---\n",
        "def constrained_BO(optimization_budget, bounds, initial_guess, all_initial_inputs, all_initial_ouputs, constraint_thresholds, xi):\n",
        "\n",
        "    # xi = exploration parameter (the larger it is, the more we explore)\n",
        "\n",
        "    # Initial values\n",
        "    # Unpack from: all_initial_ouputs: [GPur, FPur, GRec, FRec]\n",
        "    # Recovery Objectives\n",
        "    f1_vals = all_initial_ouputs[:,0]\n",
        "    f2_vals = all_initial_ouputs[:,1]\n",
        "    # print(f'f1_vals: {f1_vals}')\n",
        "    # print(f'f2_vals: {f2_vals}')\n",
        "    # Purity constraints\n",
        "    c1_vals  = all_initial_ouputs[:,2]\n",
        "    c2_vals  = all_initial_ouputs[:,3]\n",
        "    print(f'c1-size: {np.shape(c1_vals)}')\n",
        "    print(f'c2-size: {np.shape(c2_vals)}')\n",
        "\n",
        "    population = all_initial_inputs\n",
        "\n",
        "    all_inputs = np.zeros((sampling_budget+optimization_budget, 4)) # [m1, m2, m3, m4]\n",
        "    # print(f'np.shape(all_inputs):{np.shape(all_inputs)}')\n",
        "    # print(f'np.shape(all_initial_inputs):{np.shape(all_initial_inputs)}')\n",
        "    all_inputs = np.vstack((all_inputs, all_initial_inputs))\n",
        "\n",
        "    # Unpack from: all_initial_inputs\n",
        "\n",
        "    # print(f'shpae_f1_vals = {np.shape(f1_vals)}')\n",
        "\n",
        "    # Initialize where we will store solutions\n",
        "    population_all = []\n",
        "    all_constraint_1_gps = []\n",
        "    all_constraint_2_gps = []\n",
        "    ei_all = []\n",
        "\n",
        "\n",
        "    for gen in range(optimization_budget):\n",
        "        # generation = iteration\n",
        "        print(f\"\\n\\nStarting gen {gen+1}\")\n",
        "\n",
        "\n",
        "        # Generate random weights for scalarization\n",
        "        lam = np.random.rand()\n",
        "        weights = [lam, 1 - lam]\n",
        "        # print(f'weights: {weights}')\n",
        "        # Note that we generate new weights in each iteration/generation\n",
        "        # i.e. each time we update the training set\n",
        "\n",
        "        #SCALARIZE THE OBJECTIVES (BEFORE APPLYING GP)\n",
        "        scalarized_f_vals = weights[0]*f1_vals + weights[1]*f2_vals\n",
        "\n",
        "        # Fit GP to scalarized_surrogate_objective\n",
        "        # print(f'population { population}, \\nscalarized_f_vals {scalarized_f_vals} ')\n",
        "        scalarized_surrogate_gp = surrogate_model(population, scalarized_f_vals)\n",
        "        # Pull mean at relevant poputlation points\n",
        "        # Mean & Varriance\n",
        "        scalarized_surrogate_gp_mean, scalarized_surrogate_gp_std = scalarized_surrogate_gp.predict(population, return_std=True)\n",
        "        # The best value so far:\n",
        "        y_best = np.max(scalarized_surrogate_gp_mean)\n",
        "        # y_best = 0.60\n",
        "\n",
        "\n",
        "        # Fit a GP to each constraint:\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "\n",
        "            # Glu Raff Purity:\n",
        "            constraint_1_gp = surrogate_model(population, c1_vals)\n",
        "            all_constraint_1_gps.append(constraint_1_gp)\n",
        "            # Fru Ext Purity:\n",
        "            constraint_2_gp = surrogate_model(population, c2_vals)\n",
        "            all_constraint_2_gps.append(constraint_2_gp)\n",
        "\n",
        "        # Define the constraint function for the ei optimizer\n",
        "        # Constraint function with correct shape\n",
        "\n",
        "        # Define the non-linear constraint functions with dependencies\n",
        "        # note that each constraint must be written independently\n",
        "        eps = 0.1 # 5%\n",
        "        # Constraints on m1 (x0):\n",
        "        def constraint_function1(x):\n",
        "            return x[0] - (x[1] + eps*x[1])  # x0 > x1\n",
        "\n",
        "        # def constraint_function2(x):\n",
        "        #     return x[0] - (x[3] + eps*x[3])  # x0 > x3\n",
        "\n",
        "        # Constraints on m2 (x1):\n",
        "        def constraint_function3(x):\n",
        "            return x[1] - (x[0] - eps*x[0])  # x1 < x0\n",
        "\n",
        "        def constraint_function4(x):\n",
        "            return x[1] - (x[2] - eps*x[2])  # x1 < x2\n",
        "\n",
        "        # Constraints on m3 (x2):\n",
        "        def constraint_function5(x):\n",
        "            return x[2] - (x[1] + eps*x[1])  # x2 > x1\n",
        "\n",
        "        def constraint_function6(x):\n",
        "            return x[2] - (x[3] + eps*x[3])  # x2 > x3\n",
        "\n",
        "        # Constraints on m4 (x3):\n",
        "        def constraint_function7(x):\n",
        "            return x[3] - (x[2] - eps*x[2])  # x3 < x2\n",
        "\n",
        "        def constraint_function8(x):\n",
        "            return (x[0] - eps*x[0]) - x[3]  # x0 > x3\n",
        "\n",
        "        # Create the NonlinearConstraint objects\n",
        "        # Constraints on m1 (x0):\n",
        "        nonlinear_constraint1 = NonlinearConstraint(constraint_function1, 0, np.inf)\n",
        "        # nonlinear_constraint2 = NonlinearConstraint(constraint_function2, 0, np.inf)\n",
        "        # Constraints on m2 (x1):\n",
        "        nonlinear_constraint3 = NonlinearConstraint(constraint_function3, -np.inf, 0)\n",
        "        nonlinear_constraint4 = NonlinearConstraint(constraint_function4, -np.inf, 0)\n",
        "        # Constraints on m3 (x2):\n",
        "        nonlinear_constraint5 = NonlinearConstraint(constraint_function5, 0, np.inf)\n",
        "        nonlinear_constraint6 = NonlinearConstraint(constraint_function6, 0, np.inf)\n",
        "        # Constraints on m4 (x3):\n",
        "        nonlinear_constraint7 = NonlinearConstraint(constraint_function7, -np.inf, 0)\n",
        "        nonlinear_constraint8 = NonlinearConstraint(constraint_function8, 0, np.inf)\n",
        "\n",
        "\n",
        "        # --- Run the optimization ---\n",
        "        print(f'Maxing ECI')\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "\n",
        "            result = differential_evolution(\n",
        "                func=log_expected_constrained_improvement, # probability_of_improvement(x, surrogate_gp, y_best, xi=0.005), expected_improvement(x, surrogate_gp, y_best) | log_expected_constrained_improvement(x, scalarized_surrogate_gp, [constraint_1_gp, constraint_2_gp], constraint_thresholds, y_best, xi)\n",
        "                bounds=bounds,\n",
        "                args=(scalarized_surrogate_gp, [constraint_1_gp, constraint_2_gp], constraint_thresholds, y_best, xi),\n",
        "                strategy='best1bin',\n",
        "                maxiter=200,\n",
        "                popsize=15,\n",
        "                disp=False,\n",
        "                 constraints=(\n",
        "                nonlinear_constraint1, nonlinear_constraint3,\n",
        "                nonlinear_constraint4, nonlinear_constraint5, nonlinear_constraint6,\n",
        "                nonlinear_constraint7, nonlinear_constraint8)\n",
        "                 )\n",
        "\n",
        "                # Perform the optimization using L-BFGS-B method\n",
        "        # result = minimize(\n",
        "        #     expected_improvement,\n",
        "        #     initial_guess,\n",
        "        #     args=(scalarized_surrogate_gp, y_best),\n",
        "        #     method='L-BFGS-B',\n",
        "        #     bounds=bounds,\n",
        "        #     options={'maxiter': 100, 'disp': True})\n",
        "\n",
        "        x_new = result.x # [m1, m2, m3, m4]\n",
        "        # print(f\"x_new: { x_new}\")\n",
        "        f_new, c_new = obj_con(x_new, t_index_min)\n",
        "\n",
        "\n",
        "\n",
        "        # Add the new row to all_inputs\n",
        "        all_inputs = np.vstack((all_inputs, x_new))\n",
        "\n",
        "        # Add to population\n",
        "        population_all.append(population)\n",
        "        population = np.vstack((population, x_new))\n",
        "\n",
        "        f1_vals = np.vstack([f1_vals.reshape(-1,1), f_new[0]])\n",
        "        f2_vals = np.vstack([f2_vals.reshape(-1,1), f_new[1]])\n",
        "        c1_vals  = np.vstack([c1_vals.reshape(-1,1), c_new[0]])\n",
        "        c2_vals  = np.vstack([c2_vals.reshape(-1,1), c_new[1]])\n",
        "\n",
        "        print(f\"Gen {gen+1} Status:\\n | Sampled Inputs:{x_new} [m1, m2, m3, m4]|\\n Outputs: f1: {f_new[0]}, f2: {f_new[1]} | GPur, FPur: {c_new[0]}, {c_new[1]}\")\n",
        "\n",
        "    return population_all, f1_vals, f2_vals, c1_vals , c2_vals , all_inputs"
      ],
      "metadata": {
        "id": "Hc1_C2ukpT07"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Initial Inputs"
      ],
      "metadata": {
        "id": "LEpsAFFaqHAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_initial_inputs, all_initial_outputs = generate_initial_data(sampling_budget,t_index_min)\n",
        "\n",
        "print(f'all_initial_inputs{ all_initial_inputs}')\n",
        "print(f'all_initial_outputs{ all_initial_outputs}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grUZvNMrqC_j",
        "outputId": "e239011d-a84f-489b-fc34-dd80b020908e"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "np.shape(x_new)[0]: (20, 4)\n",
            "[m1, m2, m3, m4]: [0.8, 0.27, 0.53, 0.2]\n",
            "Q_internal: [4.03171057 2.57479698 3.28950931 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.26926912 11.84223351  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.27, 0.3167639392489103, 0.2]\n",
            "Q_internal: [4.03171057 2.57479698 2.70334607 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.26926912  9.73204586  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.27, 0.4656772543352231, 0.2]\n",
            "Q_internal: [4.03171057 2.57479698 3.11269293 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.26926912 11.20569453  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.2836842105263158, 0.48645168633693736, 0.2]\n",
            "Q_internal: [4.03171057 2.61241342 3.16979963 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.4046883  11.41127866  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.2836842105263158, 0.46421226099024354, 0.2]\n",
            "Q_internal: [4.03171057 2.61241342 3.10866581 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.4046883  11.19119693  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.2836842105263158, 0.4057832422939275, 0.2]\n",
            "Q_internal: [4.03171057 2.61241342 2.94805066 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.4046883  10.61298238  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.2973684210526316, 0.3959278539848955, 0.2]\n",
            "Q_internal: [4.03171057 2.65002986 2.92095925 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.54010748 10.51545329  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.2973684210526316, 0.3305809770346825, 0.2]\n",
            "Q_internal: [4.03171057 2.65002986 2.74132764 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.54010748  9.86877949  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.2973684210526316, 0.4970864069342943, 0.2]\n",
            "Q_internal: [4.03171057 2.65002986 3.19903334 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.54010748 11.51652004  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.31105263157894736, 0.47625447058498327, 0.2]\n",
            "Q_internal: [4.03171057 2.68764629 3.14176857 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.67552666 11.31036684  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.31105263157894736, 0.45865825077203326, 0.2]\n",
            "Q_internal: [4.03171057 2.68764629 3.09339843 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.67552666 11.13623435  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.31105263157894736, 0.4790741129252469, 0.2]\n",
            "Q_internal: [4.03171057 2.68764629 3.14951946 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.67552666 11.33827007  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.32473684210526316, 0.5000019357959806, 0.2]\n",
            "Q_internal: [4.03171057 2.72526273 3.20704782 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.81094584 11.54537216  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.32473684210526316, 0.5212445081711307, 0.2]\n",
            "Q_internal: [4.03171057 2.72526273 3.26544139 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.81094584 11.75558901  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.32473684210526316, 0.4742698355539805, 0.2]\n",
            "Q_internal: [4.03171057 2.72526273 3.13631302 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.81094584 11.29072686  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.33842105263157896, 0.4195388709850102, 0.2]\n",
            "Q_internal: [4.03171057 2.76287917 2.98586342 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.94636501 10.74910831  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.33842105263157896, 0.3595923365470777, 0.2]\n",
            "Q_internal: [4.03171057 2.76287917 2.82107678 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.94636501 10.1558764   8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.33842105263157896, 0.43484601278685364, 0.2]\n",
            "Q_internal: [4.03171057 2.76287917 3.02794112 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806  9.94636501 10.90058805  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.35210526315789475, 0.3889403362144265, 0.2]\n",
            "Q_internal: [4.03171057 2.80049561 2.9017513  2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806 10.08178419 10.4463047   8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "[m1, m2, m3, m4]: [0.8, 0.35210526315789475, 0.4451115246079529, 0.2]\n",
            "Q_internal: [4.03171057 2.80049561 3.05615992 2.38237443] cm^s/s\n",
            "Q_internal: [14.51415806 10.08178419 11.00217572  8.57654794] L/h\n",
            "Q_internal type: <class 'numpy.ndarray'>\n",
            "all_initial_inputs[[0.8        0.27       0.53       0.2       ]\n",
            " [0.8        0.27       0.31676394 0.2       ]\n",
            " [0.8        0.27       0.46567725 0.2       ]\n",
            " [0.8        0.28368421 0.48645169 0.2       ]\n",
            " [0.8        0.28368421 0.46421226 0.2       ]\n",
            " [0.8        0.28368421 0.40578324 0.2       ]\n",
            " [0.8        0.29736842 0.39592785 0.2       ]\n",
            " [0.8        0.29736842 0.33058098 0.2       ]\n",
            " [0.8        0.29736842 0.49708641 0.2       ]\n",
            " [0.8        0.31105263 0.47625447 0.2       ]\n",
            " [0.8        0.31105263 0.45865825 0.2       ]\n",
            " [0.8        0.31105263 0.47907411 0.2       ]\n",
            " [0.8        0.32473684 0.50000194 0.2       ]\n",
            " [0.8        0.32473684 0.52124451 0.2       ]\n",
            " [0.8        0.32473684 0.47426984 0.2       ]\n",
            " [0.8        0.33842105 0.41953887 0.2       ]\n",
            " [0.8        0.33842105 0.35959234 0.2       ]\n",
            " [0.8        0.33842105 0.43484601 0.2       ]\n",
            " [0.8        0.35210526 0.38894034 0.2       ]\n",
            " [0.8        0.35210526 0.44511152 0.2       ]]\n",
            "all_initial_outputs[[0.7313338  0.69208053 0.83080271 0.84001779]\n",
            " [0.3057092  0.82187622 0.92060758 0.7550773 ]\n",
            " [0.66747682 0.74794531 0.88625194 0.82697733]\n",
            " [0.71143349 0.72409033 0.87092449 0.84908364]\n",
            " [0.68693868 0.74073057 0.88821406 0.84411662]\n",
            " [0.59922264 0.78488457 0.91923136 0.82772946]\n",
            " [0.60001926 0.76281846 0.92336414 0.8386865 ]\n",
            " [0.40503047 0.80052693 0.93034021 0.81415237]\n",
            " [0.73744547 0.69967656 0.86068793 0.86352247]\n",
            " [0.73299227 0.695378   0.87703737 0.87052559]\n",
            " [0.71613975 0.71088016 0.89149202 0.86814762]\n",
            " [0.73628714 0.69265757 0.87466355 0.87090199]\n",
            " [0.76575479 0.65938838 0.8529761  0.88177974]\n",
            " [0.78154797 0.6545284  0.83380116 0.88566363]\n",
            " [0.74527106 0.68660445 0.87796981 0.88005715]\n",
            " [0.6908609  0.73223845 0.91586517 0.88258115]\n",
            " [0.55750098 0.76657911 0.9340464  0.87195733]\n",
            " [0.71220578 0.71712401 0.9072076  0.8842443 ]\n",
            " [0.64526854 0.73924724 0.92802651 0.88501213]\n",
            " [0.73469482 0.70065754 0.89980911 0.89221265]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPTIMIZATION LOOP"
      ],
      "metadata": {
        "id": "gGm6Rcm0q2DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "constraint_thresholds = [0.995, 0.995] # (Purity constraints) will scale with increased col#\n",
        "\n",
        "# Note that before hand, we know that:\n",
        "# (i) We want m1 to be relatively, larger than others\n",
        "m1_min, m1_max = m_max, m_max + (m_max*2)\n",
        "# (ii) We want m4 to be relatively, smaller that others\n",
        "m4_min, m4_max = m_min - (m_min*0.7), m_min\n",
        "\n",
        "bounds = [  (m1_min, m1_max), # m1\n",
        "    (m_min, m_max), # m2\n",
        "    (m_min, m_max), # m3\n",
        "    (m4_min, m4_max)  # m4\n",
        "]\n",
        "\n",
        "initial_guess = 0 # min\n",
        "population_all, f1_vals, f2_vals, c1_vals, c2_vals, all_inputs  = constrained_BO(optimization_budget, bounds, initial_guess, all_initial_inputs, all_initial_outputs, constraint_thresholds, 0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVONiTUqq4yf",
        "outputId": "ae6d29ea-d6ae-4fe2-bb82-eb4cd2a59c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c1-size: (20,)\n",
            "c2-size: (20,)\n",
            "\n",
            "\n",
            "Starting gen 1\n",
            "Maxing ECI\n",
            "np.shape(x_new)[0]: (4,)\n",
            "[m1, m2, m3, m4]: [1.5898034885148904, 0.27006749242690614, 0.30008884217877024, 0.08160507549041748]\n",
            "Q_internal: [22.3300667   9.26993703  9.56702881  7.40490978] L/h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the Pareto curve\n",
        "f1_initial = all_initial_outputs[:,0]\n",
        "f2_initial = all_initial_outputs[:,1]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(f1_vals, f2_vals, c='blue', marker='o', lable = 'Optimization Iterations')\n",
        "plt.scatter(f1_initial, f2_initial, c='grey', marker='o', lable = 'Initial Samples')\n",
        "\n",
        "plt.title(f'Pareto Curve of Recoveries of Glu in Raff  vs Fru in Ext\\n Config: {zone_config} \\nInitial Samples: {sampling_budget}, Otp Samples: {optimization_budget} ')\n",
        "plt.xlabel('Glucose Recovery in Raffinate')\n",
        "plt.ylabel('Fructose Recovery in Extract')\n",
        "plt.xlim(0, 1)\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w0KhG_batiqG",
        "outputId": "1fd3f86d-3c50-4763-efe3-7a4849baa8b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}